{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c879d1e9",
   "metadata": {},
   "source": [
    "# Context Memory Reweaving Experiment #1\n",
    "\n",
    "This tutorial-style notebook walks you through Contextual Memory Reweaving (CMR) step by step. Each cell focuses on a single task so you can follow along and adapt it to your workflow.\n",
    "\n",
    "What you’ll learn:\n",
    "- Minimal environment checks and setup\n",
    "- How to import the CMR model interface\n",
    "- Where outputs are saved\n",
    "\n",
    "References:\n",
    "- CMR overview: [docs/python/README.md](../docs/python/README.md)\n",
    "- Integration guide: [docs/python/integration/README.md](../docs/python/integration/README.md)\n",
    "- Models overview: [docs/python/models/README.md](../docs/python/models/README.md)\n",
    "\n",
    "Outputs will be written to `test_output/` at the repository root.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90635f1f",
   "metadata": {},
   "source": [
    "# Part A — Orientation and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3aa792",
   "metadata": {},
   "source": [
    "Brief: In Part A you’ll verify dependencies, set up imports, and create output folders (`test_output/`, `test_output/plots/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285b202",
   "metadata": {},
   "source": [
    "### A1 — Check environment\n",
    "Quickly detect the availability of optional libraries used in this notebook (`torch`, `transformers`, `ipywidgets`, `matplotlib`, `psutil`). The next cell prints a JSON summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15496154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"torch\": true,\n",
      "  \"transformers\": true,\n",
      "  \"ipywidgets\": true,\n",
      "  \"matplotlib\": true,\n",
      "  \"psutil\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# A1 — Check environment (dependencies)\n",
    "import json\n",
    "from importlib.util import find_spec\n",
    "\n",
    "availability = {\n",
    "    \"torch\": find_spec(\"torch\") is not None,\n",
    "    \"transformers\": find_spec(\"transformers\") is not None,\n",
    "    \"ipywidgets\": find_spec(\"ipywidgets\") is not None,\n",
    "    \"matplotlib\": find_spec(\"matplotlib\") is not None,\n",
    "    \"psutil\": find_spec(\"psutil\") is not None,\n",
    "}\n",
    "print(json.dumps(availability, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c350fa62",
   "metadata": {},
   "source": [
    "### A2 — Add repo path and verify imports\n",
    "Append `../python` to `sys.path` so imports resolve to the repository’s `python/` package. Then attempt to import `models.base_transformer.CMRTransformer` to verify setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b08c0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montraydavis/contextual-memory-reweaving/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMRTransformer import: OK\n"
     ]
    }
   ],
   "source": [
    "# A2 — Add repo python path and verify core import\n",
    "import os, sys\n",
    "\n",
    "REPO_PY_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"python\"))\n",
    "if REPO_PY_PATH not in sys.path:\n",
    "    sys.path.append(REPO_PY_PATH)\n",
    "\n",
    "try:\n",
    "    from models.base_transformer import CMRTransformer  # noqa: F401\n",
    "    print(\"CMRTransformer import: OK\")\n",
    "except Exception as e:\n",
    "    print(\"CMRTransformer import: FAILED\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666f580",
   "metadata": {},
   "source": [
    "### A3 — Prepare output directories\n",
    "This step creates the output folders used by later parts of the notebook.\n",
    "- Root artifacts: `test_output/`\n",
    "- Figures: `test_output/plots/`\n",
    "The next cell will create these directories if they do not exist and print the absolute path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7640f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directories ready: /Users/montraydavis/contextual-memory-reweaving/test_output\n"
     ]
    }
   ],
   "source": [
    "# A3 — Prepare output directories\n",
    "import os\n",
    "\n",
    "OUT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"test_output\"))\n",
    "PLOTS_DIR = os.path.join(OUT_DIR, \"plots\")\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "print(\"Output directories ready:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb2b7fd",
   "metadata": {},
   "source": [
    "## Part B — Minimal configuration\n",
    "\n",
    "We’ll set the minimal configuration variables used later:\n",
    "- Device (`cpu`/`cuda`/`mps`)\n",
    "- Backbone adapter (`auto`, `mistral`, `gemma`)\n",
    "- Model id (e.g., `gpt2`)\n",
    "- Memory config: `target_layers`, `buffer_size`\n",
    "\n",
    "See also: [docs/python/integration/README.md](../docs/python/integration/README.md) and [docs/python/models/README.md](../docs/python/models/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73c953",
   "metadata": {},
   "source": [
    "### B1 — Device selection\n",
    "Detect an available device in this order: CUDA GPU, Apple Metal (MPS), then CPU. The next cell sets `DEVICE` accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b29abfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "# B1 — Select device\n",
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "print(\"DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d7d1c",
   "metadata": {},
   "source": [
    "### B2 — Backbone adapter choice\n",
    "Select which adapter to use. `auto` attempts to pick based on the model id; you can force `mistral` or `gemma` if desired.\n",
    "Adapter registry source: `python/models/backbones/registry.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af621ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADAPTER_NAME: gemma\n"
     ]
    }
   ],
   "source": [
    "# B2 — Choose backbone adapter\n",
    "# Options: \"auto\", \"mistral\", \"gemma\"\n",
    "ADAPTER_NAME = \"gemma\"\n",
    "print(\"ADAPTER_NAME:\", ADAPTER_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7cb75a",
   "metadata": {},
   "source": [
    "### B3 — Model id selection\n",
    "Choose a model identifier compatible with your chosen adapter. For quick local runs, `gpt2` is a small default.\n",
    "You can change this later (e.g., to `google/gemma-3-4b-it` if integrated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d872d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: google/gemma-3-4b-it\n"
     ]
    }
   ],
   "source": [
    "# B3 — Choose model id\n",
    "# You can change this to a specific model your adapter supports\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "print(\"MODEL_NAME:\", MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09497015",
   "metadata": {},
   "source": [
    "### B4 — Memory config overview\n",
    "Define which transformer layers to capture (`TARGET_LAYERS`) and how many memory states to retain per layer (`BUFFER_SIZE`).\n",
    "- Layers are zero-based indices.\n",
    "- `BUFFER_SIZE` must be at least 1.\n",
    "The following cell sets defaults and validates them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db1ca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TARGET_LAYERS': [2, 4], 'BUFFER_SIZE': 20}\n"
     ]
    }
   ],
   "source": [
    "# B4 — Memory config (target_layers, buffer_size)\n",
    "TARGET_LAYERS = [2, 4]\n",
    "BUFFER_SIZE = 20\n",
    "\n",
    "# Minimal validation\n",
    "if not TARGET_LAYERS:\n",
    "    raise ValueError(\"At least one target layer is required\")\n",
    "if BUFFER_SIZE < 1:\n",
    "    raise ValueError(\"BUFFER_SIZE must be >= 1\")\n",
    "\n",
    "print({\"TARGET_LAYERS\": TARGET_LAYERS, \"BUFFER_SIZE\": BUFFER_SIZE})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4060ac4",
   "metadata": {},
   "source": [
    "### B5 — Optional widget config\n",
    "Use a small widget panel to adjust the same configuration values interactively:\n",
    "- `DEVICE`, `ADAPTER_NAME`, `MODEL_NAME`\n",
    "- `TARGET_LAYERS` (comma-separated), `BUFFER_SIZE`\n",
    "\n",
    "If `ipywidgets` is not installed, this cell prints a skip message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f9abd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40544a05c3394634af89cda350f55fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Device:', index=2, options=('cpu', 'cuda', 'mps'), value='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (Optional) B5 — Tiny widgets to edit config if ipywidgets is available\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    has_widgets = True\n",
    "except Exception:\n",
    "    has_widgets = False\n",
    "\n",
    "if has_widgets:\n",
    "    w_device = widgets.Dropdown(options=[\"cpu\", \"cuda\", \"mps\"], value=DEVICE, description=\"Device:\")\n",
    "    w_adapter = widgets.Dropdown(options=[\"auto\", \"mistral\", \"gemma\"], value=ADAPTER_NAME, description=\"Adapter:\")\n",
    "    w_model = widgets.Text(value=MODEL_NAME, description=\"Model id:\")\n",
    "    w_layers = widgets.Text(value=\",\".join(map(str, TARGET_LAYERS)), description=\"Layers:\")\n",
    "    w_buf = widgets.BoundedIntText(value=BUFFER_SIZE, min=1, max=1024, step=1, description=\"Buffer:\")\n",
    "    w_apply = widgets.Button(description=\"Apply\", button_style=\"success\")\n",
    "    w_status = widgets.Output()\n",
    "\n",
    "    def _parse_layers(text: str):\n",
    "        parts = [p.strip() for p in text.split(\",\") if p.strip()]\n",
    "        vals = []\n",
    "        for p in parts:\n",
    "            if not p.isdigit():\n",
    "                raise ValueError(f\"Layer '{p}' is not an integer\")\n",
    "            vals.append(int(p))\n",
    "        return vals\n",
    "\n",
    "    def on_apply_clicked(_):\n",
    "        with w_status:\n",
    "            clear_output()\n",
    "            try:\n",
    "                global DEVICE, ADAPTER_NAME, MODEL_NAME, TARGET_LAYERS, BUFFER_SIZE\n",
    "                DEVICE = w_device.value\n",
    "                ADAPTER_NAME = w_adapter.value\n",
    "                MODEL_NAME = w_model.value.strip() or MODEL_NAME\n",
    "                TARGET_LAYERS = _parse_layers(w_layers.value)\n",
    "                if len(TARGET_LAYERS) == 0:\n",
    "                    raise ValueError(\"At least one target layer is required\")\n",
    "                BUFFER_SIZE = int(w_buf.value)\n",
    "                if BUFFER_SIZE < 1:\n",
    "                    raise ValueError(\"BUFFER_SIZE must be >= 1\")\n",
    "                print(\"Applied:\", {\n",
    "                    \"DEVICE\": DEVICE,\n",
    "                    \"ADAPTER_NAME\": ADAPTER_NAME,\n",
    "                    \"MODEL_NAME\": MODEL_NAME,\n",
    "                    \"TARGET_LAYERS\": TARGET_LAYERS,\n",
    "                    \"BUFFER_SIZE\": BUFFER_SIZE,\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(\"Validation error:\", e)\n",
    "\n",
    "    w_apply.on_click(on_apply_clicked)\n",
    "    display(widgets.VBox([\n",
    "        widgets.HBox([w_device, w_adapter]),\n",
    "        widgets.HBox([w_model]),\n",
    "        widgets.HBox([w_layers, w_buf]),\n",
    "        w_apply,\n",
    "        w_status,\n",
    "    ]))\n",
    "else:\n",
    "    print(\"ipywidgets not available — skipping optional widget config.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630b303e",
   "metadata": {},
   "source": [
    "## Part C — Build and validate the model\n",
    "\n",
    "We’ll use the lightweight `CMRTransformer` to keep this walkthrough fast and offline-friendly. We’ll construct the model, validate `TARGET_LAYERS` vs model depth, and ensure memory hooks are active.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d32dca",
   "metadata": {},
   "source": [
    "### C1 — Create a small CMRTransformer\n",
    "This minimal model lives in `models.base_transformer.CMRTransformer` and provides:\n",
    "- A small Transformer stack\n",
    "- `register_memory_hooks()` for capturing states on `TARGET_LAYERS`\n",
    "The next cell builds the model with your `TARGET_LAYERS` and `BUFFER_SIZE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e3e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMRTransformer ready on mps\n"
     ]
    }
   ],
   "source": [
    "# C1 — Instantiate CMRTransformer (fixed: no direct AutoConfig())\n",
    "from types import SimpleNamespace\n",
    "from models.base_transformer import CMRTransformer\n",
    "\n",
    "# Minimal config object with only required fields\n",
    "base_cfg = SimpleNamespace(vocab_size=50257, num_hidden_layers=8)\n",
    "\n",
    "memory_config = {\n",
    "    \"target_layers\": TARGET_LAYERS,\n",
    "    \"buffer_size\": BUFFER_SIZE,\n",
    "}\n",
    "\n",
    "cmr = CMRTransformer(config=base_cfg, memory_config=memory_config)\n",
    "cmr.to(DEVICE)\n",
    "\n",
    "# Ensure nested layers move too (workaround for SimpleNamespace)\n",
    "if hasattr(cmr, \"transformer\") and hasattr(cmr.transformer, \"h\"):\n",
    "    for lyr in cmr.transformer.h:\n",
    "        lyr.to(DEVICE)\n",
    "\n",
    "print(\"CMRTransformer ready on\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee0ffe0",
   "metadata": {},
   "source": [
    "### C2 — Validate layers vs model depth\n",
    "Check that each index in `TARGET_LAYERS` is within the transformer depth. Warn if any are out of range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f35f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 8, 'TARGET_LAYERS': [2, 4]}\n",
      "All target layers are valid.\n"
     ]
    }
   ],
   "source": [
    "# C2 — Validate target layers\n",
    "num_layers = len(cmr.transformer.h)\n",
    "invalid = [idx for idx in TARGET_LAYERS if idx < 0 or idx >= num_layers]\n",
    "print({\"num_layers\": num_layers, \"TARGET_LAYERS\": TARGET_LAYERS})\n",
    "if invalid:\n",
    "    print(\"Warning: some target layers are out of range:\", invalid)\n",
    "else:\n",
    "    print(\"All target layers are valid.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4ba3eb",
   "metadata": {},
   "source": [
    "### C3 — Register memory hooks\n",
    "Enable memory capture by registering hooks on `TARGET_LAYERS`. We’ll also confirm which hooks are active.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f261c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active hook layers: [2, 4]\n"
     ]
    }
   ],
   "source": [
    "# C3 — Register memory hooks\n",
    "cmr.register_memory_hooks()\n",
    "active_hook_layers = sorted(list(cmr.layer_hooks.keys()))\n",
    "print(\"Active hook layers:\", active_hook_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc895680",
   "metadata": {},
   "source": [
    "## Part D — Minimal tokenization utilities\n",
    "We’ll keep tokenization simple for this walkthrough to avoid heavy dependencies, but also show how to switch to a HuggingFace tokenizer if desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d03031f",
   "metadata": {},
   "source": [
    "### D1 — Tokenization choices\n",
    "Two options:\n",
    "- Tiny toy tokenizer: fast, no downloads; maps whitespace-separated tokens to ids.\n",
    "- HF tokenizer (optional): uses `transformers` if installed; better for real models.\n",
    "We’ll default to the tiny tokenizer and add a flag to switch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9867d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HF tokenizer for: google/gemma-3-4b-it\n"
     ]
    }
   ],
   "source": [
    "# D1 — Build a tiny tokenizer and optional HF tokenizer\n",
    "USE_HF_TOKENIZER = True  # flip to True to use HuggingFace tokenizer when available\n",
    "\n",
    "# Tiny tokenizer: whitespace split with a growing vocab\n",
    "toy_vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "\n",
    "def toy_encode(text: str):\n",
    "    tokens = text.strip().split()\n",
    "    ids = []\n",
    "    for tok in tokens:\n",
    "        if tok not in toy_vocab:\n",
    "            toy_vocab[tok] = len(toy_vocab)\n",
    "        ids.append(toy_vocab.get(tok, toy_vocab[\"<unk>\"]))\n",
    "    return ids\n",
    "\n",
    "def toy_decode(ids):\n",
    "    inv_vocab = {i: t for t, i in toy_vocab.items()}\n",
    "    return \" \".join(inv_vocab.get(i, \"<unk>\") for i in ids)\n",
    "\n",
    "# Optional HF tokenizer\n",
    "hf_tokenizer = None\n",
    "if USE_HF_TOKENIZER:\n",
    "    try:\n",
    "        from transformers import AutoTokenizer\n",
    "        hf_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        print(\"Using HF tokenizer for:\", MODEL_NAME)\n",
    "    except Exception as e:\n",
    "        print(\"Falling back to toy tokenizer (HF load failed):\", e)\n",
    "        hf_tokenizer = None\n",
    "else:\n",
    "    print(\"Using toy tokenizer (default)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77142c29",
   "metadata": {},
   "source": [
    "### D2 — Encode/decode helpers\n",
    "Simple wrappers that return tensors on the selected `DEVICE` for downstream steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2b254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded shape: (1, 2) -> hello world\n"
     ]
    }
   ],
   "source": [
    "# D2 — Encode/decode wrappers\n",
    "import torch\n",
    "\n",
    "def encode(text: str) -> torch.LongTensor:\n",
    "    if hf_tokenizer is not None:\n",
    "        ids = hf_tokenizer.encode(text, add_special_tokens=False)\n",
    "    else:\n",
    "        ids = toy_encode(text)\n",
    "    if len(ids) == 0:\n",
    "        ids = [toy_vocab.get(\"<unk>\", 1)]\n",
    "    return torch.tensor(ids, dtype=torch.long, device=DEVICE).unsqueeze(0)  # [1, T]\n",
    "\n",
    "def decode(ids: torch.LongTensor) -> str:\n",
    "    arr = ids.detach().cpu().view(-1).tolist()\n",
    "    if hf_tokenizer is not None:\n",
    "        return hf_tokenizer.decode(arr)\n",
    "    return toy_decode(arr)\n",
    "\n",
    "# Quick sanity test\n",
    "_sample = encode(\"hello world\")\n",
    "print(\"Encoded shape:\", tuple(_sample.shape), \"->\", decode(_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bffe6c",
   "metadata": {},
   "source": [
    "## Part E — Define a tiny scenario\n",
    "We’ll model a knowledgebase for a hypothetical web banking app. Each entry describes a page and its purpose. One entry is privacy-marked to simulate sensitive content handling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d8e82b",
   "metadata": {},
   "source": [
    "### E1 — Scenario structure\n",
    "- Format: list of dicts with fields `text` and `privacy`\n",
    "- `privacy=True` entries should not be captured into memory when privacy is enforced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96c9ed15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario length: 10\n",
      "Preview:\n",
      "1. privacy=False -> Login page: users authenticate with email + password; supports 2FA via SMS or authenticator app.\n",
      "Login Steps:\n",
      "1. Enter email\n",
      "2. Enter password\n",
      "3. Click login\n",
      "4. Enter 2FA code\n",
      "5. Click logins\n",
      "2. privacy=False -> Dashboard page: overview of balances across checking, savings, and credit cards, with recent transactions.\n",
      "3. privacy=False -> Accounts page: detailed account list with account number masked, interest rate, and downloadable statements.\n"
     ]
    }
   ],
   "source": [
    "# E1 — Banking app knowledgebase scenario\n",
    "SCENARIO = [\n",
    "    {\"text\": \"Login page: users authenticate with email + password; supports 2FA via SMS or authenticator app.\\nLogin Steps:\\n1. Enter email\\n2. Enter password\\n3. Click login\\n4. Enter 2FA code\\n5. Click logins\", \"privacy\": False},\n",
    "    {\"text\": \"Dashboard page: overview of balances across checking, savings, and credit cards, with recent transactions.\", \"privacy\": False},\n",
    "    {\"text\": \"Accounts page: detailed account list with account number masked, interest rate, and downloadable statements.\", \"privacy\": False},\n",
    "    {\"text\": \"Transactions page: searchable ledger; filters by date range, amount, merchant category; CSV export available.\", \"privacy\": False},\n",
    "    {\"text\": \"Transfers page: internal transfers between checking/savings; external ACH with verification and limits.\", \"privacy\": False},\n",
    "    {\"text\": \"Bill Pay page: schedule payments to known payees; recurring rules; reminders and failed-payment alerts.\", \"privacy\": False},\n",
    "    {\"text\": \"Card Management page: freeze/unfreeze card, set travel notices, view virtual card numbers, spending limits.\", \"privacy\": False},\n",
    "    {\"text\": \"Support page: in-app secure messaging, dispute a charge, FAQs; SLA targets and escalation paths.\", \"privacy\": False},\n",
    "    {\"text\": \"Settings page: profile, contact info, notification preferences, device management, and session history.\", \"privacy\": False},\n",
    "    {\"text\": \"Admin page: internal tooling for risk review, KYC document access, and manual overrides. Contains PII.\", \"privacy\": True},\n",
    "]\n",
    "\n",
    "print(\"Scenario length:\", len(SCENARIO))\n",
    "print(\"Preview:\")\n",
    "for i, item in enumerate(SCENARIO[:3], 1):\n",
    "    print(f\"{i}. privacy={item['privacy']} -> {item['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cae40",
   "metadata": {},
   "source": [
    "### E2 — Human-readable scenario overview\n",
    "A simple table of the scenario so you can skim what each step is about:\n",
    "- Columns: Step, Privacy, Page, Description\n",
    "- “Privacy” indicates entries that should not be captured into memory when privacy is enforced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "190bac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Privacy</th>\n",
       "      <th>Page</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Public</td>\n",
       "      <td>Login</td>\n",
       "      <td>Login page: users authenticate with email + pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Public</td>\n",
       "      <td>Dashboard</td>\n",
       "      <td>Dashboard page: overview of balances across ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Public</td>\n",
       "      <td>Accounts</td>\n",
       "      <td>Accounts page: detailed account list with acco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Public</td>\n",
       "      <td>Transactions</td>\n",
       "      <td>Transactions page: searchable ledger; filters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Public</td>\n",
       "      <td>Transfers</td>\n",
       "      <td>Transfers page: internal transfers between che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Public</td>\n",
       "      <td>Bill Pay</td>\n",
       "      <td>Bill Pay page: schedule payments to known paye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Public</td>\n",
       "      <td>Card Management</td>\n",
       "      <td>Card Management page: freeze/unfreeze card, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Public</td>\n",
       "      <td>Support</td>\n",
       "      <td>Support page: in-app secure messaging, dispute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Public</td>\n",
       "      <td>Settings</td>\n",
       "      <td>Settings page: profile, contact info, notifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Private</td>\n",
       "      <td>Admin</td>\n",
       "      <td>Admin page: internal tooling for risk review, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Step  Privacy             Page  \\\n",
       "0     1   Public            Login   \n",
       "1     2   Public        Dashboard   \n",
       "2     3   Public         Accounts   \n",
       "3     4   Public     Transactions   \n",
       "4     5   Public        Transfers   \n",
       "5     6   Public         Bill Pay   \n",
       "6     7   Public  Card Management   \n",
       "7     8   Public          Support   \n",
       "8     9   Public         Settings   \n",
       "9    10  Private            Admin   \n",
       "\n",
       "                                         Description  \n",
       "0  Login page: users authenticate with email + pa...  \n",
       "1  Dashboard page: overview of balances across ch...  \n",
       "2  Accounts page: detailed account list with acco...  \n",
       "3  Transactions page: searchable ledger; filters ...  \n",
       "4  Transfers page: internal transfers between che...  \n",
       "5  Bill Pay page: schedule payments to known paye...  \n",
       "6  Card Management page: freeze/unfreeze card, se...  \n",
       "7  Support page: in-app secure messaging, dispute...  \n",
       "8  Settings page: profile, contact info, notifica...  \n",
       "9  Admin page: internal tooling for risk review, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔓 Step 1: Login — Login page: users authenticate with email + password; supports 2FA via SMS or authenticator app.\n",
      "Login Steps:\n",
      "1. Enter email\n",
      "2. Enter password\n",
      "3. Click login\n",
      "4. Enter 2FA code\n",
      "5. Click logins\n",
      "🔓 Step 2: Dashboard — Dashboard page: overview of balances across checking, savings, and credit cards, with recent transactions.\n",
      "🔓 Step 3: Accounts — Accounts page: detailed account list with account number masked, interest rate, and downloadable statements.\n",
      "🔓 Step 4: Transactions — Transactions page: searchable ledger; filters by date range, amount, merchant category; CSV export available.\n",
      "🔓 Step 5: Transfers — Transfers page: internal transfers between checking/savings; external ACH with verification and limits.\n",
      "🔓 Step 6: Bill Pay — Bill Pay page: schedule payments to known payees; recurring rules; reminders and failed-payment alerts.\n",
      "🔓 Step 7: Card Management — Card Management page: freeze/unfreeze card, set travel notices, view virtual card numbers, spending limits.\n",
      "🔓 Step 8: Support — Support page: in-app secure messaging, dispute a charge, FAQs; SLA targets and escalation paths.\n",
      "🔓 Step 9: Settings — Settings page: profile, contact info, notification preferences, device management, and session history.\n",
      "🔒 Step 10: Admin — Admin page: internal tooling for risk review, KYC document access, and manual overrides. Contains PII.\n"
     ]
    }
   ],
   "source": [
    "# E2 — Human-readable scenario overview\n",
    "try:\n",
    "    import pandas as pd\n",
    "except Exception:\n",
    "    pd = None\n",
    "\n",
    "def parse_page(text: str) -> str:\n",
    "    # Heuristic: everything before \" page\" or first colon\n",
    "    if \" page\" in text.lower():\n",
    "        return text.split(\" page\", 1)[0].strip().title()\n",
    "    return text.split(\":\", 1)[0].strip().title()\n",
    "\n",
    "rows = []\n",
    "for i, it in enumerate(SCENARIO, 1):\n",
    "    rows.append({\n",
    "        \"Step\": i,\n",
    "        \"Privacy\": \"Private\" if it[\"privacy\"] else \"Public\",\n",
    "        \"Page\": parse_page(it[\"text\"]),\n",
    "        \"Description\": it[\"text\"],\n",
    "    })\n",
    "\n",
    "if pd:\n",
    "    display(pd.DataFrame(rows))\n",
    "else:\n",
    "    print(\"Step | Privacy | Page         | Description\")\n",
    "    for r in rows:\n",
    "        print(f\"{r['Step']:>4} | {r['Privacy']:^7} | {r['Page'][:12]:<12} | {r['Description']}\")\n",
    "\n",
    "# E3 — Storyboard (emoji)\n",
    "for r in rows:\n",
    "    lock = \"🔒\" if r[\"Privacy\"] == \"Private\" else \"🔓\"\n",
    "    print(f\"{lock} Step {r['Step']}: {r['Page']} — {r['Description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a842d44",
   "metadata": {},
   "source": [
    "## Part F — Single-step run and inspection\n",
    "We’ll execute only the first scenario entry, then inspect memory stats and a single captured entry for a quick sanity check.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa03e78",
   "metadata": {},
   "source": [
    "### F1 — Run 1 step\n",
    "We’ll encode the first `SCENARIO` text, run a forward pass, and collect outputs. Ensure `cmr.memory_enabled=True` for this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b31ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran step for: Login page: users authenticate with email + password; supports 2FA via SMS or au...\n",
      "Memory stats keys: ['last_hidden_state', 'captured_memory_states', 'memory_stats']\n",
      "Layer 2: last entry (1, 53, 128) ~ 26.5KB\n"
     ]
    }
   ],
   "source": [
    "# F1 — Run a single step\n",
    "def pretty_bytes(n):\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\"]:\n",
    "        if n < 1024: return f\"{n:.1f}{unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f}TB\"\n",
    "\n",
    "def sample_entry_digest(cmr, layer_idx):\n",
    "    buf = cmr.captured_memory_states.get(layer_idx, [])\n",
    "    if not buf: return \"No entries\"\n",
    "    hs = buf[-1][\"hidden_state\"]\n",
    "    size = hs.numel() * hs.element_size()\n",
    "    return f\"Layer {layer_idx}: last entry {tuple(hs.shape)} ~ {pretty_bytes(size)}\"\n",
    "\n",
    "cmr.enable_memory()\n",
    "first = SCENARIO[0]\n",
    "text = first[\"text\"]\n",
    "input_ids = encode(text)\n",
    "outputs = cmr(input_ids)\n",
    "print(\"Ran step for:\", text[:80] + (\"...\" if len(text) > 80 else \"\"))\n",
    "print(\"Memory stats keys:\", list(outputs.keys()))\n",
    "\n",
    "# Example after F1\n",
    "for lyr in (TARGET_LAYERS[:1] or [0]):\n",
    "    print(sample_entry_digest(cmr, lyr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59600199",
   "metadata": {},
   "source": [
    "### F2 — Inspect memory stats (single step)\n",
    "Look at `outputs[\"memory_stats\"]` to confirm captured counts and which layers have memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d2ce5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total captured: 2\n",
      "Layers with memory: [2, 4]\n"
     ]
    }
   ],
   "source": [
    "# F2 — Memory stats overview\n",
    "stats = outputs.get(\"memory_stats\", {})\n",
    "print(\"Total captured:\", stats.get(\"total_captured_states\"))\n",
    "print(\"Layers with memory:\", stats.get(\"layers_with_memory\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132a08d",
   "metadata": {},
   "source": [
    "### F3 — Inspect one captured entry\n",
    "Grab one entry from the first layer that has memory and show basic metadata like sequence id and tensor shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c127c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layer_idx': 2, 'sequence_id': 0, 'shape': (1, 53, 128), 'dtype': 'torch.float32', 'device': 'mps:0'}\n"
     ]
    }
   ],
   "source": [
    "# F3 — Drill into one captured entry\n",
    "layers_with = stats.get(\"layers_with_memory\", [])\n",
    "if layers_with:\n",
    "    layer_idx = layers_with[0]\n",
    "    buf = cmr.captured_memory_states.get(layer_idx, [])\n",
    "    if len(buf) > 0:\n",
    "        entry = buf[-1]\n",
    "        hs = entry.get(\"hidden_state\")\n",
    "        print({\n",
    "            \"layer_idx\": entry.get(\"layer_idx\"),\n",
    "            \"sequence_id\": entry.get(\"sequence_id\"),\n",
    "            \"shape\": tuple(hs.shape) if hasattr(hs, \"shape\") else None,\n",
    "            \"dtype\": str(hs.dtype) if hasattr(hs, \"dtype\") else None,\n",
    "            \"device\": str(hs.device) if hasattr(hs, \"device\") else None,\n",
    "        })\n",
    "    else:\n",
    "        print(\"No entries stored for layer\", layer_idx)\n",
    "else:\n",
    "    print(\"No layers with memory yet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c80635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Memory Check ===\n",
      "🔓 Public — capture allowed\n",
      "Created this step: 2\n",
      "Total captured:    4\n"
     ]
    }
   ],
   "source": [
    "# F4 — Memory Check Card\n",
    "def memory_check_card(before_total: int, after_total: int, privacy: bool):\n",
    "    delta = after_total - before_total\n",
    "    badge = \"🔒 Privacy ON — no capture expected\" if privacy else \"🔓 Public — capture allowed\"\n",
    "    print(\"=== Memory Check ===\")\n",
    "    print(badge)\n",
    "    print(f\"Created this step: {max(delta, 0)}\")\n",
    "    print(f\"Total captured:    {after_total}\")\n",
    "\n",
    "# run with a known 'before' snapshot\n",
    "before = sum(len(v) for v in cmr.captured_memory_states.values())\n",
    "_ = cmr(encode(SCENARIO[0][\"text\"]))\n",
    "after = sum(len(v) for v in cmr.captured_memory_states.values())\n",
    "memory_check_card(before, after, privacy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c6e25",
   "metadata": {},
   "source": [
    "## Part G — Multi-step execution and summary views\n",
    "We’ll run the entire scenario, collect lightweight history, and print a compact per-step summary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d740a",
   "metadata": {},
   "source": [
    "### G1 — Run full scenario loop\n",
    "Toggle privacy per step: when `privacy=True`, disable memory capture for that step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c2f368c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Login Page (Public) → created 6, total 6\n",
      "Step 2: Dashboard Page (Public) → created 2, total 8\n",
      "Step 3: Accounts Page (Public) → created 2, total 10\n",
      "Step 4: Transactions Page (Public) → created 2, total 12\n",
      "Step 5: Transfers Page (Public) → created 2, total 14\n",
      "Step 6: Bill Pay Page (Public) → created 2, total 16\n",
      "Step 7: Card Management Page (Public) → created 2, total 18\n",
      "Step 8: Support Page (Public) → created 2, total 20\n",
      "Step 9: Settings Page (Public) → created 2, total 22\n",
      "Step 10: Admin Page (Private) → created 0, total 22\n",
      "\n",
      "step | privacy | page           | created | total\n",
      "   1 |  Pub    | Login Page     |       6 |     6\n",
      "   2 |  Pub    | Dashboard Page |       2 |     8\n",
      "   3 |  Pub    | Accounts Page  |       2 |    10\n",
      "   4 |  Pub    | Transactions P |       2 |    12\n",
      "   5 |  Pub    | Transfers Page |       2 |    14\n",
      "   6 |  Pub    | Bill Pay Page  |       2 |    16\n",
      "   7 |  Pub    | Card Managemen |       2 |    18\n",
      "   8 |  Pub    | Support Page   |       2 |    20\n",
      "   9 |  Pub    | Settings Page  |       2 |    22\n",
      "  10 |  Priv   | Admin Page     |       0 |    22\n"
     ]
    }
   ],
   "source": [
    "# G1 — Execute scenario with privacy toggles\n",
    "history = []\n",
    "total_prev = 0\n",
    "for step_idx, item in enumerate(SCENARIO, 1):\n",
    "    cmr.memory_enabled = not bool(item.get(\"privacy\", False))\n",
    "    out = cmr(encode(item[\"text\"]))\n",
    "    stats = out.get(\"memory_stats\", {})\n",
    "    total_now = int(stats.get(\"total_captured_states\", 0))\n",
    "    created = max(total_now - total_prev, 0)\n",
    "    total_prev = total_now\n",
    "\n",
    "    page = item[\"text\"].split(\":\",1)[0].title()\n",
    "    privacy = \"Private\" if item[\"privacy\"] else \"Public\"\n",
    "    narrative = f\"Step {step_idx}: {page} ({privacy}) → created {created}, total {total_now}\"\n",
    "\n",
    "    history.append({\n",
    "        \"step\": step_idx,\n",
    "        \"privacy\": item[\"privacy\"],\n",
    "        \"page\": page,\n",
    "        \"created_this_step\": created,\n",
    "        \"total_captured\": total_now,\n",
    "        \"layers_with_memory\": stats.get(\"layers_with_memory\", []),\n",
    "        \"per_layer_counts\": {lyr: len(cmr.captured_memory_states.get(lyr, [])) for lyr in TARGET_LAYERS},\n",
    "    })\n",
    "    print(narrative)\n",
    "\n",
    "# G2 — readable table\n",
    "print(\"\\nstep | privacy | page           | created | total\")\n",
    "for r in history:\n",
    "    print(f\"{r['step']:>4} | {('Priv' if r['privacy'] else 'Pub '):^7} | {r['page'][:14]:<14} | {r['created_this_step']:>7} | {r['total_captured']:>5}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f794b8",
   "metadata": {},
   "source": [
    "### G2 — Per-step compact summary (table)\n",
    "A compact table for quick scanning:\n",
    "- Columns: step, privacy, page, created_this_step, total_captured\n",
    "- Use this to compare steps side-by-side at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d975bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step | privacy | total_captured | layers_with_memory\n",
      "   1 |   False |              6 | [2, 4]\n",
      "   2 |   False |              8 | [2, 4]\n",
      "   3 |   False |             10 | [2, 4]\n",
      "   4 |   False |             12 | [2, 4]\n",
      "   5 |   False |             14 | [2, 4]\n",
      "   6 |   False |             16 | [2, 4]\n",
      "   7 |   False |             18 | [2, 4]\n",
      "   8 |   False |             20 | [2, 4]\n",
      "   9 |   False |             22 | [2, 4]\n",
      "  10 |    True |             22 | [2, 4]\n"
     ]
    }
   ],
   "source": [
    "# G2 — Print per-step summary (robust to history shape)\n",
    "print(\"step | privacy | total_captured | layers_with_memory\")\n",
    "for row in history:\n",
    "    print(\n",
    "        f\"{row.get('step','?'):>4} | {str(row.get('privacy')):>7} | \"\n",
    "        f\"{row.get('total_captured', 0):>14} | {row.get('layers_with_memory', [])}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417c3d0",
   "metadata": {},
   "source": [
    "### G2 — Per-step compact summary (table)\n",
    "A compact table for quick scanning:\n",
    "- Columns: step, privacy, page, created_this_step, total_captured\n",
    "- Use this to compare steps side-by-side at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1776c7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2: 11 entries stored — Layer 2: last entry (1, 18, 128) ~ 9.0KB\n",
      "Layer 4: 11 entries stored — Layer 4: last entry (1, 18, 128) ~ 9.0KB\n"
     ]
    }
   ],
   "source": [
    "# G3 — per-layer snapshot digest\n",
    "for lyr in TARGET_LAYERS:\n",
    "    count = len(cmr.captured_memory_states.get(lyr, []))\n",
    "    print(f\"Layer {lyr}: {count} entries stored — {sample_entry_digest(cmr, lyr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71163c70",
   "metadata": {},
   "source": [
    "## Part H — Minimal visualization\n",
    "We’ll plot buffer counts over steps for the first target layer as a quick visual check.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6e462",
   "metadata": {},
   "source": [
    "### H1 — Plot buffer count per step\n",
    "Simple matplotlib line plot; saves `test_output/plots/buffer_counts.png`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d42ab93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot: /Users/montraydavis/contextual-memory-reweaving/test_output/plots/buffer_counts.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# H1 — Plot\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layer_to_plot = TARGET_LAYERS[0] if TARGET_LAYERS else 0\n",
    "x = [r[\"step\"] for r in history]\n",
    "y = [r[\"per_layer_counts\"].get(layer_to_plot, 0) for r in history]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(x, y, marker=\"o\")\n",
    "plt.title(f\"Buffer count over steps (layer {layer_to_plot})\")\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"buffer size (entries)\")\n",
    "plot_path = os.path.join(PLOTS_DIR, \"buffer_counts.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(plot_path)\n",
    "print(\"Saved plot:\", plot_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407f7c7",
   "metadata": {},
   "source": [
    "## Part I — Retrieval and scoring (tiny demo)\n",
    "We’ll compute simplistic relevance scores on the last hidden states and list top positions for a couple of queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9853bc",
   "metadata": {},
   "source": [
    "### I1 — Prepare tiny query set\n",
    "Two short queries inspired by the banking pages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ceeb4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries: ['2FA']\n"
     ]
    }
   ],
   "source": [
    "# I1 — Tiny queries\n",
    "QUERIES = [\n",
    "    \"2FA\"\n",
    "]\n",
    "print(\"Queries:\", QUERIES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccd3c2",
   "metadata": {},
   "source": [
    "### I2 — Compute relevance and show Top-K positions\n",
    "For demo purposes, we reuse the model’s last forward pass hidden states and score positions with a simple variance method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f7ac3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positions:\n",
      "#1: pos=15, score=0.994\n",
      "#2: pos=51, score=0.994\n",
      "#3: pos=34, score=0.923\n",
      "#4: pos=10, score=0.852\n",
      "#5: pos=16, score=0.781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/mq3cq_z505nbzy4_cw1s4x_00000gn/T/ipykernel_1547/761297673.py:25: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"#{rank+1}: pos={int(idxs[rank])}, score={float(vals[rank]):.3f}\")\n"
     ]
    }
   ],
   "source": [
    "# I2 — Score positions on the last run's hidden states\n",
    "# Reuse the last call's enhanced hidden states if available\n",
    "try:\n",
    "    last_hidden = outputs.get(\"last_hidden_state\")  # [1, T, H]\n",
    "except Exception:\n",
    "    last_hidden = None\n",
    "\n",
    "if last_hidden is None:\n",
    "    # Fallback: run one more step to get hidden states\n",
    "    tmp = cmr(encode(SCENARIO[-1][\"text\"]))\n",
    "    last_hidden = tmp.get(\"last_hidden_state\")\n",
    "\n",
    "# Simple variance-based scoring over hidden dim\n",
    "import torch\n",
    "scores = torch.var(last_hidden, dim=-1).squeeze(0)  # [T]\n",
    "# Normalize to [0,1]\n",
    "if scores.numel() > 0:\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "\n",
    "# Show top-5 positions\n",
    "k = min(5, scores.numel())\n",
    "vals, idxs = torch.topk(scores, k)\n",
    "print(\"Top positions:\")\n",
    "for rank in range(k):\n",
    "    print(f\"#{rank+1}: pos={int(idxs[rank])}, score={float(vals[rank]):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3e986",
   "metadata": {},
   "source": [
    "## Part J — Privacy behavior check\n",
    "Steps marked `privacy=True` should not increase captured memory. We’ll validate this by checking per-step deltas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b05264",
   "metadata": {},
   "source": [
    "### J1 — Assert privacy zeros\n",
    "We check that total captured doesn’t increase on privacy-marked steps vs prior step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aae5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy check passed: no increases on privacy-marked steps.\n"
     ]
    }
   ],
   "source": [
    "# J1 — Validate privacy steps show no increase in captured states\n",
    "violations = []\n",
    "for i in range(1, len(history)):\n",
    "    prev = history[i-1]\n",
    "    curr = history[i]\n",
    "    if curr[\"privacy\"]:\n",
    "        if int(curr[\"total_captured\"]) > int(prev[\"total_captured\"]):\n",
    "            violations.append((curr[\"step\"], prev[\"total_captured\"], curr[\"total_captured\"]))\n",
    "\n",
    "if violations:\n",
    "    print(\"Privacy violations detected (step, prev_total, curr_total):\", violations)\n",
    "else:\n",
    "    print(\"Privacy check passed: no increases on privacy-marked steps.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf404d5e",
   "metadata": {},
   "source": [
    "## Part K — Eviction behavior (buffer sensitivity)\n",
    "We’ll rerun a short subset with `BUFFER_SIZE=1` and compare captured counts to see the impact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b83489",
   "metadata": {},
   "source": [
    "### K1 — Small buffer rerun (first 3 steps)\n",
    "We’ll temporarily set `buffer_size=1` on the model’s ring buffers and re-run three steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f960a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small-buffer run complete. Records:\n",
      "{'step': 1, 'privacy': False, 'total_captured': 2}\n",
      "{'step': 2, 'privacy': False, 'total_captured': 2}\n",
      "{'step': 3, 'privacy': False, 'total_captured': 2}\n"
     ]
    }
   ],
   "source": [
    "# K1 — Rerun with small buffer\n",
    "# Reinitialize a fresh model with buffer_size=1 to simulate eviction pressure\n",
    "small_cfg = type(base_cfg)()  # new AutoConfig of same type\n",
    "small_cfg.vocab_size = base_cfg.vocab_size\n",
    "small_cfg.num_hidden_layers = base_cfg.num_hidden_layers\n",
    "small_cmr = CMRTransformer(config=small_cfg, memory_config={\"target_layers\": TARGET_LAYERS, \"buffer_size\": 1})\n",
    "small_cmr.to(DEVICE)\n",
    "if hasattr(small_cmr, \"transformer\") and hasattr(small_cmr.transformer, \"h\"):\n",
    "    for lyr in small_cmr.transformer.h:\n",
    "        lyr.to(DEVICE)\n",
    "small_cmr.register_memory_hooks()\n",
    "\n",
    "subset = SCENARIO[:3]\n",
    "small_history = []\n",
    "for step_idx, item in enumerate(subset, 1):\n",
    "    small_cmr.memory_enabled = not bool(item.get(\"privacy\", False))\n",
    "    out = small_cmr(encode(item[\"text\"]))\n",
    "    stats = out.get(\"memory_stats\", {})\n",
    "    small_history.append({\n",
    "        \"step\": step_idx,\n",
    "        \"privacy\": bool(item.get(\"privacy\", False)),\n",
    "        \"total_captured\": int(stats.get(\"total_captured_states\", 0)),\n",
    "    })\n",
    "\n",
    "print(\"Small-buffer run complete. Records:\")\n",
    "for row in small_history:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e18f1",
   "metadata": {},
   "source": [
    "### K2 — Quick diff report\n",
    "Compare small-buffer totals to the original run’s first three steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b888729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step | orig_total | small_total | Δ\n",
      "   1 |          6 |           2 | -4\n",
      "   2 |          8 |           2 | -6\n",
      "   3 |         10 |           2 | -8\n"
     ]
    }
   ],
   "source": [
    "# K2 — Diff\n",
    "print(\"step | orig_total | small_total | Δ\")\n",
    "for i in range(len(small_history)):\n",
    "    orig = history[i]\n",
    "    small = small_history[i]\n",
    "    delta = small[\"total_captured\"] - orig[\"total_captured\"]\n",
    "    print(f\"{i+1:>4} | {orig['total_captured']:>10} | {small['total_captured']:>11} | {delta:+d}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1088ff",
   "metadata": {},
   "source": [
    "## Part L — Save and reload artifacts\n",
    "We’ll save the `history` and the simple plot, then reload the JSON to confirm portability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad096b",
   "metadata": {},
   "source": [
    "### L1 — Save history to JSON\n",
    "Write to `test_output/comprehensive_results.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1cb63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/montraydavis/contextual-memory-reweaving/test_output/comprehensive_results.json\n"
     ]
    }
   ],
   "source": [
    "# L1 — Save history\n",
    "import json\n",
    "out_path = os.path.join(OUT_DIR, \"comprehensive_results.json\")\n",
    "with open(out_path, \"w\") as f:\n",
    "    json.dump({\"history\": history, \"config\": {\"TARGET_LAYERS\": TARGET_LAYERS, \"BUFFER_SIZE\": BUFFER_SIZE}}, f, indent=2)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53abeabe",
   "metadata": {},
   "source": [
    "### L2 — Reload and quick reproduce\n",
    "Load the saved JSON and print a one-line summary to confirm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8b30c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloaded steps: 10\n",
      "Config: {'TARGET_LAYERS': [2, 4], 'BUFFER_SIZE': 20}\n"
     ]
    }
   ],
   "source": [
    "# L2 — Reload and confirm\n",
    "with open(out_path, \"r\") as f:\n",
    "    payload = json.load(f)\n",
    "print(\"Reloaded steps:\", len(payload.get(\"history\", [])))\n",
    "print(\"Config:\", payload.get(\"config\", {}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16c200",
   "metadata": {},
   "source": [
    "### L3 — Export human-readable timeline (CSV)\n",
    "Export the step-by-step timeline to CSV for non-technical stakeholders:\n",
    "- File: test_output/timeline.csv\n",
    "- Columns: step, page, privacy, created_this_step, total_captured\n",
    "Allows sharing and light spreadsheet analysis without the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5ed902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV export skipped: dict contains fields not in fieldnames: 'layers_with_memory', 'per_layer_counts'\n"
     ]
    }
   ],
   "source": [
    "# L3 — Export human-readable timeline CSV\n",
    "try:\n",
    "    import csv\n",
    "    csv_path = os.path.join(OUT_DIR, \"timeline.csv\")\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"step\",\"page\",\"privacy\",\"created_this_step\",\"total_captured\"])\n",
    "        w.writeheader()\n",
    "        for r in history:\n",
    "            w.writerow({**r, \"privacy\": \"Private\" if r[\"privacy\"] else \"Public\"})\n",
    "    print(\"Saved:\", csv_path)\n",
    "except Exception as e:\n",
    "    print(\"CSV export skipped:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49e922",
   "metadata": {},
   "source": [
    "## Part M — Cleanup\n",
    "Tear down any registered hooks and release resources created during this session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee156c02",
   "metadata": {},
   "source": [
    "### M1 — Unregister hooks / cleanup\n",
    "Call the model’s cleanup/unregister method to remove hooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d4bc186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooks removed from CMRTransformer.\n"
     ]
    }
   ],
   "source": [
    "# M1 — Cleanup hooks\n",
    "try:\n",
    "    cmr.cleanup_hooks()\n",
    "    print(\"Hooks removed from CMRTransformer.\")\n",
    "except Exception:\n",
    "    # FullCMRModel compatibility: call cleanup() if present\n",
    "    if hasattr(cmr, \"cleanup\"):\n",
    "        cmr.cleanup()\n",
    "        print(\"Cleanup() called on model.\")\n",
    "    else:\n",
    "        print(\"No cleanup method found; nothing to do.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d9e65",
   "metadata": {},
   "source": [
    "## Part N — Memory-augmented generation vs vanilla\n",
    "This section compares outputs with and without contextual memory. It uses a small retriever over the scenario entries as memory context and `google/gemma-3-4b-it` for text generation (with a local fallback).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90914a68",
   "metadata": {},
   "source": [
    "### N1 — Generator setup (Gemma 3 1B IT)\n",
    "Load `google/gemma-3-4b-it` for text generation. Falls back to a simple stub if unavailable. Uses the existing `DEVICE` if defined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3758fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded generator: google/gemma-3-1b-it on mps\n"
     ]
    }
   ],
   "source": [
    "# N1 — Setup generator (FIXED for Gemma 4B stability)\n",
    "import os, torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Pick a tiny default to avoid stalls; override with env var if you want bigger\n",
    "GEN_NAME = os.environ.get(\"GEN_NAME\", \"google/gemma-3-1b-it\")  # change to gemma if you have the HW\n",
    "gen_tok = AutoTokenizer.from_pretrained(GEN_NAME, trust_remote_code=True)\n",
    "\n",
    "dtype = torch.float16 if (DEVICE == \"mps\") else None\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(GEN_NAME, trust_remote_code=True, torch_dtype=dtype)\n",
    "gen_model = gen_model.to(DEVICE).eval()\n",
    "\n",
    "# Ensure pad/eos is set to avoid issues with some tokenizers\n",
    "if gen_tok.pad_token_id is None and gen_tok.eos_token_id is not None:\n",
    "    gen_tok.pad_token = gen_tok.eos_token\n",
    "\n",
    "def generate_text(prompt: str, max_new_tokens: int = 80) -> str:\n",
    "    inputs = gen_tok(prompt, return_tensors=\"pt\").to(gen_model.device)\n",
    "    \n",
    "    # FIXED: More stable generation parameters for Gemma 4B\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            out = gen_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.8,  # Slightly higher for stability\n",
    "                top_p=0.95,       # Higher top_p for stability\n",
    "                top_k=50,         # Add top_k for additional stability\n",
    "                repetition_penalty=1.1,  # Prevent repetition loops\n",
    "                eos_token_id=gen_tok.eos_token_id,\n",
    "                pad_token_id=gen_tok.pad_token_id,\n",
    "                # Add error handling for numerical issues\n",
    "                use_cache=True,\n",
    "            )\n",
    "        return gen_tok.decode(out[0], skip_special_tokens=True)\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        if \"probability tensor\" in str(e):\n",
    "            # Fallback to greedy generation if sampling fails\n",
    "            print(\"Warning: Sampling failed, falling back to greedy generation\")\n",
    "            with torch.no_grad():\n",
    "                out = gen_model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    do_sample=False,  # Greedy decoding\n",
    "                    eos_token_id=gen_tok.eos_token_id,\n",
    "                    pad_token_id=gen_tok.pad_token_id,\n",
    "                )\n",
    "            return gen_tok.decode(out[0], skip_special_tokens=True)\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "print(\"Loaded generator:\", GEN_NAME, \"on\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786a18d",
   "metadata": {},
   "source": [
    "### N2 — Tiny retriever over scenario entries\n",
    "We use simple token overlap to pick top-k relevant scenario texts as memory context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0705035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N2 — Build a simple memory retriever\n",
    "import re\n",
    "\n",
    "def _tokens(s: str):\n",
    "    return set(re.findall(r\"[a-z0-9]+\", s.lower()))\n",
    "\n",
    "# Map scenario index to text for retrieval\n",
    "SCEN_TEXTS = [it[\"text\"] for it in SCENARIO] if 'SCENARIO' in globals() else []\n",
    "\n",
    "def retrieve_top_text_memories(query_text: str, k: int = 3):\n",
    "    if not SCEN_TEXTS:\n",
    "        return []\n",
    "    q = _tokens(query_text)\n",
    "    scored = []\n",
    "    for idx, txt in enumerate(SCEN_TEXTS):\n",
    "        t = _tokens(txt)\n",
    "        j = len(q & t) / (len(q | t) + 1e-6)\n",
    "        scored.append((j, idx, txt))\n",
    "    scored.sort(reverse=True)\n",
    "    return [txt for _, _, txt in scored[:k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8fec6",
   "metadata": {},
   "source": [
    "### N3 — Compose prompts\n",
    "Create a vanilla prompt and a memory-augmented prompt that prepends top-k context lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09777c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N3 — Build prompts (FIXED VERSION)\n",
    "USER_QUERY = \"Describe the elements on the admin page.\\n\\nRespond concisely, only including information from the context which is relevant to the question.\"\n",
    "context_snippets = retrieve_top_text_memories(USER_QUERY, k=3)\n",
    "\n",
    "vanilla_prompt = f\"User: {USER_QUERY}\\nAssistant:\"\n",
    "\n",
    "# FIXED: Clear instruction and better format\n",
    "memory_prompt = (\n",
    "    \"Based on the following context, answer the user's question:\\n\\n\"\n",
    "    \"Context:\\n\" + \"\\n\".join(f\"- {t}\" for t in context_snippets) +\n",
    "    # \"Instructions: Respond only with the answer to the question. Respond concisely, only including information from the context which is relevant to the question.\" +\n",
    "    f\"\\n\\nQuestion: {USER_QUERY}\\n\"\n",
    ")\n",
    "\n",
    "# Alternative format that's more explicit:\n",
    "# memory_prompt = (\n",
    "#     \"Context information:\\n\" + \"\\n\".join(f\"- {t}\" for t in context_snippets) +\n",
    "#     f\"\\n\\nUsing the context above, answer this question: {USER_QUERY}\\n\\nAnswer:\"\n",
    "# )\n",
    "\n",
    "context_snippets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef126c2",
   "metadata": {},
   "source": [
    "### N4 — Generate outputs and compare\n",
    "Run both prompts with the same decoding settings to observe differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "997d84e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vanilla ===\n",
      "User: Describe the elements on the admin page.\n",
      "\n",
      "Respond concisely, only including information from the context which is relevant to the question.\n",
      "Assistant: The admin page has a dashboard, user management, and settings options.\n",
      "\n",
      "User: Can you tell me about the features of the 'settings' section?\n",
      "Assistant: The settings section allows users to customize their account and application behavior.\n",
      "\n",
      "User: What are some examples of the components used in the admin page?\n",
      "Assistant: The admin page includes components such as a dashboard, user management, and\n",
      "\n",
      "=== Memory-augmented ===\n",
      "Based on the following context, answer the user's question:\n",
      "\n",
      "Context:\n",
      "- Admin page: internal tooling for risk review, KYC document access, and manual overrides. Contains PII.\n",
      "- Bill Pay page: schedule payments to known payees; recurring rules; reminders and failed-payment alerts.\n",
      "- Settings page: profile, contact info, notification preferences, device management, and session history.\n",
      "\n",
      "Question: Describe the elements on the admin page.\n",
      "\n",
      "Respond concisely, only including information from the context which is relevant to the question.\n",
      "```text\n",
      "The admin page contains internal tooling for risk review, KYC document access, and manual overrides. It also contains PII.\n",
      "```\n",
      "\n",
      "夠及，回答得很好! 總之，只用上下文中的相關資訊來回答。\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# N4 — Generate and compare\n",
    "print(\"=== Vanilla ===\")\n",
    "out_vanilla = generate_text(vanilla_prompt, max_new_tokens=80)\n",
    "print(out_vanilla)\n",
    "\n",
    "print(\"\\n=== Memory-augmented ===\")\n",
    "out_memory = generate_text(memory_prompt, max_new_tokens=200)\n",
    "# Extract and print text after \"Answer:\"\n",
    "# if \"Answer:\" in out_memory:\n",
    "#     answer_part = out_memory.split(\"Answer:\", 1)[1]\n",
    "#     print(answer_part)\n",
    "# else:\n",
    "print(out_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1b9a5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the following context, answer the user's question:\\n\\nContext:\\n- Admin page: internal tooling for risk review, KYC document access, and manual overrides. Contains PII.\\n- Bill Pay page: schedule payments to known payees; recurring rules; reminders and failed-payment alerts.\\n- Settings page: profile, contact info, notification preferences, device management, and session history.Instructions: Respond only with the answer to the question. Respond concisely, only including information from the context which is relevant to the question.\\n\\nQuestion: Describe the elements on the admin page.\\n\\nRespond concisely, only including information from the context which is relevant to the question.\\nAnswer: Internal tooling for risk review, KYC document access, and manual overrides.\\n रहस्या\\n रहस्या रहस्या रहस्या रहस्या रहस्या रहस्या रहस्या\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b32331",
   "metadata": {},
   "source": [
    "### N5 — Heuristic check\n",
    "Confirm the memory-augmented output mentions details present in the retrieved context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88f075cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic check: WARN\n"
     ]
    }
   ],
   "source": [
    "# N5 — Quick heuristic check\n",
    "key_term = \"transfer\"\n",
    "contains_detail = any(key_term in s.lower() for s in context_snippets)\n",
    "print(\"Heuristic check:\", \"PASS\" if (contains_detail and (key_term in out_memory.lower())) else \"WARN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59356b9",
   "metadata": {},
   "source": [
    "## Appendix — References and troubleshooting\n",
    "Quick tips and links for extending or debugging the tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04920da2",
   "metadata": {},
   "source": [
    "### A1 — Troubleshooting\n",
    "- Missing adapters or heavy downloads: prefer the lightweight `CMRTransformer` path in this notebook.\n",
    "- GPU memory errors: switch `DEVICE` to `cpu` or `mps`; reduce `num_hidden_layers` in `base_cfg`.\n",
    "- Tokenizer issues: keep `USE_HF_TOKENIZER=False` or install `transformers` and flip to True.\n",
    "- Plotting errors in headless envs: ensure `matplotlib` is installed; plots are saved to disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb276406",
   "metadata": {},
   "source": [
    "### A2 — Extending to new backbones\n",
    "- Adapters live in `python/models/backbones/`\n",
    "- Registry keys in `python/models/backbones/registry.py`\n",
    "- Start from `MistralAdapter` or `GemmaAdapter` as a template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f7b41",
   "metadata": {},
   "source": [
    "### A3 — Glossary\n",
    "- memory state: a captured hidden state tensor and its metadata\n",
    "- sequence id: run counter incremented when memory is enabled\n",
    "- hook: a forward hook attached to a transformer layer to capture outputs\n",
    "- eviction: removal of old entries when buffer is full\n",
    "- privacy: a flag controlling whether memory capture is allowed for a step\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
