{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96cb1377",
   "metadata": {},
   "source": [
    "## Environment Setup and Dependency Verification\n",
    "\n",
    "This initial section establishes the foundational environment for working with the Contextual Memory Reweaving (CMR) system. The setup process involves three critical steps: path configuration, import verification, and device detection.\n",
    "\n",
    "### Path Configuration\n",
    "\n",
    "The notebook dynamically locates the repository's Python package by constructing an absolute path to the `../python` directory. This approach ensures that imports resolve correctly regardless of where the notebook is executed within the project structure. The path is only added to `sys.path` if it's not already present, preventing duplicate entries.\n",
    "\n",
    "### Import Verification\n",
    "\n",
    "We verify that the core `CMRTransformer` class can be imported successfully from `models.base_transformer`. This import test serves as an early validation that:\n",
    "- The Python package structure is correct\n",
    "- All required dependencies are installed\n",
    "- The core CMR classes are accessible\n",
    "\n",
    "### Device Detection and Optimization\n",
    "\n",
    "The system automatically detects the best available compute device using PyTorch's built-in detection methods:\n",
    "- **CUDA**: For NVIDIA GPU acceleration\n",
    "- **MPS**: For Apple Silicon (M1/M2) GPU acceleration  \n",
    "- **CPU**: Fallback for systems without GPU support\n",
    "\n",
    "This automatic device selection ensures optimal performance across different hardware configurations while maintaining compatibility.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **Portable Setup**: Works across different development environments\n",
    "- **Early Error Detection**: Catches configuration issues before model initialization\n",
    "- **Performance Optimization**: Automatically selects the best available hardware\n",
    "- **Development Flexibility**: Supports both local development and production deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f137d6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montraydavis/contextual-memory-reweaving/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMRTransformer import: OK\n",
      "DEVICE: mps\n"
     ]
    }
   ],
   "source": [
    "# A2 â€” Add repo python path and verify core import\n",
    "import os, sys\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "REPO_PY_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"python\"))\n",
    "if REPO_PY_PATH not in sys.path:\n",
    "    sys.path.append(REPO_PY_PATH)\n",
    "\n",
    "try:\n",
    "    from models.base_transformer import CMRTransformer  # noqa: F401\n",
    "    print(\"CMRTransformer import: OK\")\n",
    "except Exception as e:\n",
    "    print(\"CMRTransformer import: FAILED\", e)\n",
    "\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "REPO_PY_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"python\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb7cd8",
   "metadata": {},
   "source": [
    "## Configuration Management and Validation\n",
    "\n",
    "This section establishes the core configuration parameters that control the CMR system's behavior. The configuration is designed to be both flexible and robust, with built-in validation to prevent common configuration errors.\n",
    "\n",
    "### Model Selection and Adapter Configuration\n",
    "\n",
    "The configuration specifies which base model to use and how to adapt it for memory enhancement:\n",
    "- **ADAPTER_NAME**: Identifies the specific adapter implementation (e.g., \"gemma\", \"mistral\")\n",
    "- **MODEL_NAME**: Specifies the HuggingFace model identifier for the base transformer\n",
    "\n",
    "### Memory Architecture Parameters\n",
    "\n",
    "Two critical parameters control the memory system's architecture:\n",
    "\n",
    "#### Target Layers\n",
    "`TARGET_LAYERS = [2, 4]` specifies which transformer layers will have memory hooks installed. The choice of layers is strategic:\n",
    "- **Early layers** (2): Capture lower-level linguistic features and patterns\n",
    "- **Middle layers** (4): Capture higher-level semantic representations\n",
    "- **Multiple layers**: Enable hierarchical memory capture across different abstraction levels\n",
    "\n",
    "#### Buffer Management\n",
    "`BUFFER_SIZE = 20` sets the maximum number of memory entries that can be stored per layer. This parameter balances:\n",
    "- **Memory capacity**: Larger buffers retain more historical context\n",
    "- **Computational efficiency**: Smaller buffers reduce retrieval overhead\n",
    "- **Relevance**: Optimal size depends on the specific use case and task requirements\n",
    "\n",
    "### Tokenization Strategy\n",
    "\n",
    "The configuration supports dual tokenization approaches:\n",
    "- **HuggingFace Tokenizer**: Production-ready, model-specific tokenization when available\n",
    "- **Toy Tokenizer**: Lightweight fallback for development and testing scenarios\n",
    "\n",
    "### Configuration Validation\n",
    "\n",
    "Built-in validation ensures configuration integrity:\n",
    "- **Layer validation**: Verifies target layers exist in the model architecture\n",
    "- **Buffer validation**: Ensures buffer size is positive and reasonable\n",
    "- **Dependency checks**: Validates required components are available\n",
    "\n",
    "This comprehensive configuration system provides the foundation for reliable, optimized CMR operation across diverse deployment scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cde64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TARGET_LAYERS': [2, 4], 'BUFFER_SIZE': 20}\n"
     ]
    }
   ],
   "source": [
    "ADAPTER_NAME = \"gemma\"\n",
    "MODEL_NAME = \"google/gemma-3-4b-it\"\n",
    "\n",
    "TARGET_LAYERS = [2, 4]\n",
    "BUFFER_SIZE = 20\n",
    "\n",
    "# Build a tiny tokenizer and optional HF tokenizer\n",
    "USE_HF_TOKENIZER = True  # flip to True to use HuggingFace tokenizer when available\n",
    "\n",
    "# Optional HF tokenizer\n",
    "hf_tokenizer = None\n",
    "\n",
    "# Tiny tokenizer: whitespace split with a growing vocab\n",
    "toy_vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "\n",
    "# Minimal validation\n",
    "if not TARGET_LAYERS:\n",
    "    raise ValueError(\"At least one target layer is required\")\n",
    "if BUFFER_SIZE < 1:\n",
    "    raise ValueError(\"BUFFER_SIZE must be >= 1\")\n",
    "\n",
    "print({\"TARGET_LAYERS\": TARGET_LAYERS, \"BUFFER_SIZE\": BUFFER_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60597f3d",
   "metadata": {},
   "source": [
    "## Comprehensive Dataset and Scenario Framework\n",
    "\n",
    "This section establishes a rich, realistic dataset that simulates a complete web application ecosystem. The scenario is carefully designed to test the CMR system's ability to distinguish between public and private information while demonstrating contextual memory retrieval capabilities.\n",
    "\n",
    "### Scenario Architecture\n",
    "\n",
    "The dataset models a typical enterprise web application with 57 distinct pages, representing the full spectrum of modern web functionality:\n",
    "\n",
    "#### Public Pages (31 pages)\n",
    "These represent standard, openly accessible web content:\n",
    "- **Marketing pages**: Home, About, Products, Pricing\n",
    "- **User engagement**: Blog, Events, News, Help Center\n",
    "- **Functional pages**: Login, Register, Search, Shopping Cart\n",
    "- **Information pages**: Terms of Service, Privacy Policy, API Documentation\n",
    "\n",
    "#### Private/Administrative Pages (26 pages)\n",
    "These represent sensitive, access-controlled functionality:\n",
    "- **Administrative interfaces**: Admin Dashboard, User Management, Database Admin\n",
    "- **Financial systems**: Payment Processing, Financial Reports, Billing Management\n",
    "- **Security systems**: Security Center, Audit Trail, Configuration Manager\n",
    "- **HR and Legal**: Employee Portal, HR Management, Legal Documents Manager\n",
    "\n",
    "### Privacy Classification System\n",
    "\n",
    "Each scenario entry includes a binary privacy flag that enables testing of:\n",
    "- **Access control awareness**: The system can learn to distinguish public vs. private content\n",
    "- **Context-sensitive retrieval**: Memory queries can respect privacy boundaries\n",
    "- **Compliance scenarios**: Demonstrates handling of sensitive information (PII, financial data)\n",
    "\n",
    "### Content Complexity and Realism\n",
    "\n",
    "Each page description includes:\n",
    "- **Functional details**: Specific features and capabilities\n",
    "- **Technical components**: Forms, widgets, databases, APIs\n",
    "- **Business context**: Workflows, permissions, and operational requirements\n",
    "- **Compliance markers**: Explicit PII and sensitivity indicators\n",
    "\n",
    "### Utility Functions\n",
    "\n",
    "#### Page Name Extraction\n",
    "The `parse_page()` function intelligently extracts concise page names from verbose descriptions using heuristic rules:\n",
    "- Identifies page type keywords (\"page\", \"interface\", \"dashboard\")\n",
    "- Extracts meaningful titles while preserving context\n",
    "- Handles edge cases and variations in description format\n",
    "\n",
    "#### Data Structure Generation\n",
    "The dataset is systematically converted into a structured format with consistent fields:\n",
    "- **Step**: Sequential ordering for processing\n",
    "- **Privacy**: Clear public/private classification\n",
    "- **Page**: Clean, standardized page names\n",
    "- **Description**: Full descriptive content for memory storage\n",
    "\n",
    "This comprehensive scenario framework provides an ideal testing ground for evaluating CMR's ability to capture, classify, and retrieve contextual information in realistic enterprise environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4ca939",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO = [\n",
    "  {\"text\": \"Home page: company overview, featured products, testimonials, and call-to-action buttons for sign-up.\", \"privacy\": False},\n",
    "  {\"text\": \"About page: company history, mission statement, team bios, and office locations with contact details.\", \"privacy\": False},\n",
    "  {\"text\": \"Products page: catalog of available services with pricing tiers, feature comparisons, and demo videos.\", \"privacy\": False},\n",
    "  {\"text\": \"Contact page: contact form, phone numbers, email addresses, live chat widget, and business hours.\", \"privacy\": False},\n",
    "  {\"text\": \"Blog page: articles, tutorials, industry news, and SEO-optimized content with comment sections.\", \"privacy\": False},\n",
    "  {\"text\": \"Pricing page: subscription plans, feature matrix, annual vs monthly billing, and enterprise quotes.\", \"privacy\": False},\n",
    "  {\"text\": \"FAQ page: common questions organized by category with search functionality and helpful resources.\", \"privacy\": False},\n",
    "  {\"text\": \"Terms of Service page: legal agreements, user responsibilities, limitation of liability, and dispute resolution.\", \"privacy\": False},\n",
    "  {\"text\": \"Privacy Policy page: data collection practices, cookie usage, third-party integrations, and user rights.\", \"privacy\": False},\n",
    "  {\"text\": \"Careers page: open positions, company culture, benefits overview, and application submission portal.\", \"privacy\": False},\n",
    "  {\"text\": \"Login page: user authentication with email/password, social login options, and forgot password recovery.\", \"privacy\": False},\n",
    "  {\"text\": \"Register page: new user sign-up form with email verification, terms acceptance, and account activation.\", \"privacy\": False},\n",
    "  {\"text\": \"User Dashboard: personalized homepage showing account status, recent activity, and quick action buttons.\", \"privacy\": False},\n",
    "  {\"text\": \"Profile Settings: user information management, password changes, notification preferences, and account deletion.\", \"privacy\": False},\n",
    "  {\"text\": \"Billing page: payment methods, invoice history, subscription management, and upgrade/downgrade options.\", \"privacy\": False},\n",
    "  {\"text\": \"Order History: past purchases, order tracking, return requests, and downloadable receipts.\", \"privacy\": False},\n",
    "  {\"text\": \"Shopping Cart: selected items, quantity adjustments, coupon codes, and checkout initiation.\", \"privacy\": False},\n",
    "  {\"text\": \"Checkout page: shipping information, payment processing, order review, and purchase confirmation.\", \"privacy\": False},\n",
    "  {\"text\": \"Search Results: product/content listings with filters, sorting options, and pagination controls.\", \"privacy\": False},\n",
    "  {\"text\": \"Help Center: knowledge base articles, video tutorials, troubleshooting guides, and ticket submission.\", \"privacy\": False},\n",
    "  {\"text\": \"API Documentation: endpoint references, authentication methods, code examples, and rate limiting info.\", \"privacy\": False},\n",
    "  {\"text\": \"Downloads page: software installers, user manuals, templates, and resource files with version history.\", \"privacy\": False},\n",
    "  {\"text\": \"News page: press releases, company announcements, media coverage, and investor relations updates.\", \"privacy\": False},\n",
    "  {\"text\": \"Events page: upcoming webinars, conferences, product launches, and registration forms.\", \"privacy\": False},\n",
    "  {\"text\": \"Partners page: integration listings, affiliate program details, and partner application process.\", \"privacy\": False},\n",
    "  {\"text\": \"Sitemap page: hierarchical website structure with all public pages listed and organized by category.\", \"privacy\": False},\n",
    "  {\"text\": \"404 Error page: custom not found message with navigation suggestions and search functionality.\", \"privacy\": False},\n",
    "  {\"text\": \"Maintenance page: scheduled downtime notification with estimated completion time and status updates.\", \"privacy\": False},\n",
    "  {\"text\": \"Security page: data protection measures, compliance certifications, and security best practices.\", \"privacy\": False},\n",
    "  {\"text\": \"Mobile App page: download links for iOS/Android, feature highlights, and screenshot gallery.\", \"privacy\": False},\n",
    "  {\"text\": \"Integrations page: third-party service connections, setup instructions, and compatibility matrix.\", \"privacy\": False},\n",
    "  {\"text\": \"Admin Dashboard: system overview, user management controls, analytics data, and configuration settings. Contains administrative functions.\", \"privacy\": True},\n",
    "  {\"text\": \"User Management: admin interface for viewing user accounts, permissions, suspension controls, and personal data. Contains PII.\", \"privacy\": True},\n",
    "  {\"text\": \"Analytics Panel: detailed usage statistics, user behavior tracking, conversion metrics, and sensitive business data.\", \"privacy\": True},\n",
    "  {\"text\": \"Database Admin: direct database access, query execution, backup management, and sensitive system data.\", \"privacy\": True},\n",
    "  {\"text\": \"Financial Reports: revenue data, transaction details, tax information, and confidential business metrics.\", \"privacy\": True},\n",
    "  {\"text\": \"Employee Portal: staff directory, salary information, performance reviews, and internal communications. Contains PII.\", \"privacy\": True},\n",
    "  {\"text\": \"System Logs: server logs, error tracking, security events, and debugging information with user data.\", \"privacy\": True},\n",
    "  {\"text\": \"Configuration Manager: system settings, API keys, database credentials, and infrastructure management.\", \"privacy\": True},\n",
    "  {\"text\": \"Backup Interface: data recovery tools, backup scheduling, restore functions, and system maintenance access.\", \"privacy\": True},\n",
    "  {\"text\": \"Security Center: threat monitoring, access logs, vulnerability scans, and incident response tools.\", \"privacy\": True},\n",
    "  {\"text\": \"Payment Processing: transaction management, refund processing, merchant settings, and financial data access.\", \"privacy\": True},\n",
    "  {\"text\": \"Customer Support Admin: ticket management, user impersonation, chat monitoring, and PII access for support.\", \"privacy\": True},\n",
    "  {\"text\": \"Marketing Analytics: campaign performance, customer segments, A/B test results, and behavioral data.\", \"privacy\": True},\n",
    "  {\"text\": \"Content Management: CMS backend, publishing controls, media library, and editorial workflow management.\", \"privacy\": True},\n",
    "  {\"text\": \"API Management: endpoint monitoring, rate limiting controls, usage analytics, and developer key management.\", \"privacy\": True},\n",
    "  {\"text\": \"Audit Trail: compliance logging, user activity tracking, data access records, and regulatory reporting.\", \"privacy\": True},\n",
    "  {\"text\": \"HR Management: employee records, hiring pipeline, payroll data, and confidential personnel information. Contains PII.\", \"privacy\": True},\n",
    "  {\"text\": \"Legal Documents Manager: contracts, NDAs, compliance files, and confidential legal correspondence.\", \"privacy\": True},\n",
    "  {\"text\": \"Vendor Management: supplier contracts, payment processing, vendor onboarding, and procurement data.\", \"privacy\": True},\n",
    "  {\"text\": \"Executive Dashboard: board reports, strategic metrics, competitive analysis, and confidential business intelligence.\", \"privacy\": True},\n",
    "  {\"text\": \"Data Export Tool: bulk data extraction, customer information downloads, and sensitive data migration utilities. Contains PII.\", \"privacy\": True},\n",
    "  {\"text\": \"Email Campaign Manager: subscriber lists, email templates, delivery tracking, and customer communication data.\", \"privacy\": True},\n",
    "  {\"text\": \"Inventory Management: stock levels, supplier information, cost data, and warehouse operations interface.\", \"privacy\": True},\n",
    "  {\"text\": \"Customer Service Tools: case management, escalation procedures, customer history access, and support metrics.\", \"privacy\": True},\n",
    "  {\"text\": \"Quality Assurance: testing environments, bug tracking, performance monitoring, and development tools access.\", \"privacy\": True},\n",
    "  {\"text\": \"Compliance Dashboard: regulatory reporting, audit preparation, policy management, and risk assessment tools.\", \"privacy\": True}\n",
    "]\n",
    "\n",
    "STOPWORDS = [\n",
    "    \"0o\", \"0s\", \"3a\", \"3b\", \"3d\", \"6b\", \"6o\", \"a\", \"a1\", \"a2\", \"a3\", \"a4\", \"ab\", \"able\", \"about\", \"above\", \"abst\", \"ac\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"ad\", \"added\", \"adj\", \"ae\", \"af\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"ag\", \"again\", \"against\", \"ah\", \"ain\", \"ain't\", \"aj\", \"al\", \"all\", \"allow\", \"allows\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"ao\", \"ap\", \"apart\", \"apparently\", \"appear\", \"appreciate\", \"appropriate\", \"approximately\", \"ar\", \"are\", \"aren\", \"arent\", \"aren't\", \"arise\", \"around\", \"as\", \"a's\", \"aside\", \"ask\", \"asking\", \"associated\", \"at\", \"au\", \"auth\", \"av\", \"available\", \"aw\", \"away\", \"awfully\", \"ax\", \"ay\", \"az\", \"b\", \"b1\", \"b2\", \"b3\", \"ba\", \"back\", \"bc\", \"bd\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"best\", \"better\", \"between\", \"beyond\", \"bi\", \"bill\", \"biol\", \"bj\", \"bk\", \"bl\", \"bn\", \"both\", \"bottom\", \"bp\", \"br\", \"brief\", \"briefly\", \"bs\", \"bt\", \"bu\", \"but\", \"bx\", \"by\", \"c\", \"c1\", \"c2\", \"c3\", \"ca\", \"call\", \"came\", \"can\", \"cannot\", \"cant\", \"can't\", \"cause\", \"causes\", \"cc\", \"cd\", \"ce\", \"certain\", \"certainly\", \"cf\", \"cg\", \"ch\", \"changes\", \"ci\", \"cit\", \"cj\", \"cl\", \"clearly\", \"cm\", \"c'mon\", \"cn\", \"co\", \"com\", \"come\", \"comes\", \"con\", \"concerning\", \"consequently\", \"consider\", \"considering\", \"contain\", \"containing\", \"contains\", \"corresponding\", \"could\", \"couldn\", \"couldnt\", \"couldn't\", \"course\", \"cp\", \"cq\", \"cr\", \"cry\", \"cs\", \"c's\", \"ct\", \"cu\", \"currently\", \"cv\", \"cx\", \"cy\", \"cz\", \"d\", \"d2\", \"da\", \"date\", \"dc\", \"dd\", \"de\", \"definitely\", \"describe\", \"described\", \"despite\", \"detail\", \"df\", \"di\", \"did\", \"didn\", \"didn't\", \"different\", \"dj\", \"dk\", \"dl\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"done\", \"don't\", \"down\", \"downwards\", \"dp\", \"dr\", \"ds\", \"dt\", \"du\", \"due\", \"during\", \"dx\", \"dy\", \"e\", \"e2\", \"e3\", \"ea\", \"each\", \"ec\", \"ed\", \"edu\", \"ee\", \"ef\", \"effect\", \"eg\", \"ei\", \"eight\", \"eighty\", \"either\", \"ej\", \"el\", \"eleven\", \"else\", \"elsewhere\", \"em\", \"empty\", \"en\", \"end\", \"ending\", \"enough\", \"entirely\", \"eo\", \"ep\", \"eq\", \"er\", \"es\", \"especially\", \"est\", \"et\", \"et-al\", \"etc\", \"eu\", \"ev\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"exactly\", \"example\", \"except\", \"ey\", \"f\", \"f2\", \"fa\", \"far\", \"fc\", \"few\", \"ff\", \"fi\", \"fifteen\", \"fifth\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"fix\", \"fj\", \"fl\", \"fn\", \"fo\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"forty\", \"found\", \"four\", \"fr\", \"from\", \"front\", \"fs\", \"ft\", \"fu\", \"full\", \"further\", \"furthermore\", \"fy\", \"g\", \"ga\", \"gave\", \"ge\", \"get\", \"gets\", \"getting\", \"gi\", \"give\", \"given\", \"gives\", \"giving\", \"gj\", \"gl\", \"go\", \"goes\", \"going\", \"gone\", \"got\", \"gotten\", \"gr\", \"greetings\", \"gs\", \"gy\", \"h\", \"h2\", \"h3\", \"had\", \"hadn\", \"hadn't\", \"happens\", \"hardly\", \"has\", \"hasn\", \"hasnt\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"hed\", \"he'd\", \"he'll\", \"hello\", \"help\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"here's\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"he's\", \"hh\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"hj\", \"ho\", \"home\", \"hopefully\", \"how\", \"howbeit\", \"however\", \"how's\", \"hr\", \"hs\", \"http\", \"hu\", \"hundred\", \"hy\", \"i\", \"i2\", \"i3\", \"i4\", \"i6\", \"i7\", \"i8\", \"ia\", \"ib\", \"ibid\", \"ic\", \"id\", \"i'd\", \"ie\", \"if\", \"ig\", \"ignored\", \"ih\", \"ii\", \"ij\", \"il\", \"i'll\", \"im\", \"i'm\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inasmuch\", \"inc\", \"indeed\", \"index\", \"indicate\", \"indicated\", \"indicates\", \"information\", \"inner\", \"insofar\", \"instead\", \"interest\", \"into\", \"invention\", \"inward\", \"io\", \"ip\", \"iq\", \"ir\", \"is\", \"isn\", \"isn't\", \"it\", \"itd\", \"it'd\", \"it'll\", \"its\", \"it's\", \"itself\", \"iv\", \"i've\", \"ix\", \"iy\", \"iz\", \"j\", \"jj\", \"jr\", \"js\", \"jt\", \"ju\", \"just\", \"k\", \"ke\", \"keep\", \"keeps\", \"kept\", \"kg\", \"kj\", \"km\", \"know\", \"known\", \"knows\", \"ko\", \"l\", \"l2\", \"la\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"lb\", \"lc\", \"le\", \"least\", \"les\", \"less\", \"lest\", \"let\", \"lets\", \"let's\", \"lf\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"lj\", \"ll\", \"ll\", \"ln\", \"lo\", \"look\", \"looking\", \"looks\", \"los\", \"lr\", \"ls\", \"lt\", \"ltd\", \"m\", \"m2\", \"ma\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"mightn\", \"mightn't\", \"mill\", \"million\", \"mine\", \"miss\", \"ml\", \"mn\", \"mo\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"mr\", \"mrs\", \"ms\", \"mt\", \"mu\", \"much\", \"mug\", \"must\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"n\", \"n2\", \"na\", \"name\", \"namely\", \"nay\", \"nc\", \"nd\", \"ne\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needn\", \"needn't\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"ng\", \"ni\", \"nine\", \"ninety\", \"nj\", \"nl\", \"nn\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"novel\", \"now\", \"nowhere\", \"nr\", \"ns\", \"nt\", \"ny\", \"o\", \"oa\", \"ob\", \"obtain\", \"obtained\", \"obviously\", \"oc\", \"od\", \"of\", \"off\", \"often\", \"og\", \"oh\", \"oi\", \"oj\", \"ok\", \"okay\", \"ol\", \"old\", \"om\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"oo\", \"op\", \"oq\", \"or\", \"ord\", \"os\", \"ot\", \"other\", \"others\", \"otherwise\", \"ou\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"ow\", \"owing\", \"own\", \"ox\", \"oz\", \"p\", \"p1\", \"p2\", \"p3\", \"page\", \"pagecount\", \"pages\", \"par\", \"part\", \"particular\", \"particularly\", \"pas\", \"past\", \"pc\", \"pd\", \"pe\", \"per\", \"perhaps\", \"pf\", \"ph\", \"pi\", \"pj\", \"pk\", \"pl\", \"placed\", \"please\", \"plus\", \"pm\", \"pn\", \"po\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"pq\", \"pr\", \"predominantly\", \"present\", \"presumably\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"ps\", \"pt\", \"pu\", \"put\", \"py\", \"q\", \"qj\", \"qu\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"r2\", \"ra\", \"ran\", \"rather\", \"rc\", \"rd\", \"re\", \"readily\", \"really\", \"reasonably\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"research-articl\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"rf\", \"rh\", \"ri\", \"right\", \"rj\", \"rl\", \"rm\", \"rn\", \"ro\", \"rq\", \"rr\", \"rs\", \"rt\", \"ru\", \"run\", \"rv\", \"ry\", \"s\", \"s2\", \"sa\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sc\", \"sd\", \"se\", \"sec\", \"second\", \"secondly\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sensible\", \"sent\", \"serious\", \"seriously\", \"seven\", \"several\", \"sf\", \"shall\", \"shan\", \"shan't\", \"she\", \"shed\", \"she'd\", \"she'll\", \"shes\", \"she's\", \"should\", \"shouldn\", \"shouldn't\", \"should've\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"si\", \"side\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"sincere\", \"six\", \"sixty\", \"sj\", \"sl\", \"slightly\", \"sm\", \"sn\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"sp\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"sq\", \"sr\", \"ss\", \"st\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure\", \"sy\", \"system\", \"sz\", \"t\", \"t1\", \"t2\", \"t3\", \"take\", \"taken\", \"taking\", \"tb\", \"tc\", \"td\", \"te\", \"tell\", \"ten\", \"tends\", \"tf\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that's\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"there's\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'd\", \"they'll\", \"theyre\", \"they're\", \"they've\", \"thickv\", \"thin\", \"think\", \"third\", \"this\", \"thorough\", \"thoroughly\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"three\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"ti\", \"til\", \"tip\", \"tj\", \"tl\", \"tm\", \"tn\", \"to\", \"together\", \"too\", \"took\", \"top\", \"toward\", \"towards\", \"tp\", \"tq\", \"tr\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"t's\", \"tt\", \"tv\", \"twelve\", \"twenty\", \"twice\", \"two\", \"tx\", \"u\", \"u201d\", \"ue\", \"ui\", \"uj\", \"uk\", \"um\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"uo\", \"up\", \"upon\", \"ups\", \"ur\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"ut\", \"v\", \"va\", \"value\", \"various\", \"vd\", \"ve\", \"ve\", \"very\", \"via\", \"viz\", \"vj\", \"vo\", \"vol\", \"vols\", \"volumtype\", \"vq\", \"vs\", \"vt\", \"vu\", \"w\", \"wa\", \"want\", \"wants\", \"was\", \"wasn\", \"wasnt\", \"wasn't\", \"way\", \"we\", \"wed\", \"we'd\", \"welcome\", \"well\", \"we'll\", \"well-b\", \"went\", \"were\", \"we're\", \"weren\", \"werent\", \"weren't\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"what's\", \"when\", \"whence\", \"whenever\", \"when's\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"where's\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"who's\", \"whose\", \"why\", \"why's\", \"wi\", \"widely\", \"will\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wo\", \"won\", \"wonder\", \"wont\", \"won't\", \"words\", \"world\", \"would\", \"wouldn\", \"wouldnt\", \"wouldn't\", \"www\", \"x\", \"x1\", \"x2\", \"x3\", \"xf\", \"xi\", \"xj\", \"xk\", \"xl\", \"xn\", \"xo\", \"xs\", \"xt\", \"xv\", \"xx\", \"y\", \"y2\", \"yes\", \"yet\", \"yj\", \"yl\", \"you\", \"youd\", \"you'd\", \"you'll\", \"your\", \"youre\", \"you're\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"yr\", \"ys\", \"yt\", \"z\", \"zero\", \"zi\", \"zz\"\n",
    "]\n",
    "\n",
    "def parse_page(text: str) -> str:\n",
    "    # Heuristic: everything before \" page\" or first colon\n",
    "    if \" page\" in text.lower():\n",
    "        return text.split(\" page\", 1)[0].strip().title()\n",
    "    return text.split(\":\", 1)[0].strip().title()\n",
    "\n",
    "rows = []\n",
    "for i, it in enumerate(SCENARIO, 1):\n",
    "    rows.append({\n",
    "        \"Step\": i,\n",
    "        \"Privacy\": \"Private\" if it[\"privacy\"] else \"Public\",\n",
    "        \"Page\": parse_page(it[\"text\"]),\n",
    "        \"Description\": it[\"text\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15826a6c",
   "metadata": {},
   "source": [
    "## CMRTransformer Initialization and Architecture Setup\n",
    "\n",
    "This section demonstrates the core process of instantiating and configuring a CMRTransformer instance, which serves as the foundation for all memory-enhanced operations in the CMR system.\n",
    "\n",
    "### Minimal Configuration Strategy\n",
    "\n",
    "The initialization uses a `SimpleNamespace` object to provide only the essential configuration parameters required by the CMRTransformer:\n",
    "\n",
    "#### Core Parameters\n",
    "- **vocab_size**: Set to 50,257 (GPT-2 standard vocabulary size) for tokenization compatibility\n",
    "- **num_hidden_layers**: Set to 8 layers, providing sufficient depth for meaningful memory capture\n",
    "\n",
    "This minimal approach ensures compatibility while avoiding unnecessary configuration complexity that might cause initialization failures with incomplete model configurations.\n",
    "\n",
    "### Memory Configuration Architecture\n",
    "\n",
    "The `memory_config` dictionary specifies the memory system's operational parameters:\n",
    "\n",
    "#### Target Layer Selection\n",
    "```python\n",
    "\"target_layers\": TARGET_LAYERS  # [2, 4]\n",
    "```\n",
    "Configures which transformer layers will have memory hooks installed. The selection of layers 2 and 4 is strategic:\n",
    "- **Layer 2**: Captures early semantic representations and linguistic patterns\n",
    "- **Layer 4**: Captures more abstract, higher-level conceptual information\n",
    "- **Multi-layer approach**: Enables hierarchical memory capture across different levels of abstraction\n",
    "\n",
    "#### Buffer Management\n",
    "```python\n",
    "\"buffer_size\": BUFFER_SIZE  # 20\n",
    "```\n",
    "Sets the maximum number of memory entries that can be stored per layer, balancing memory capacity with computational efficiency.\n",
    "\n",
    "### Device Management and Optimization\n",
    "\n",
    "The CMRTransformer is moved to the optimal available device (CPU/GPU/MPS) for best performance. The additional device assignment for nested layers addresses a specific technical consideration:\n",
    "\n",
    "#### Nested Layer Device Assignment\n",
    "When using `SimpleNamespace` configurations (instead of full HuggingFace configs), nested transformer layers may not automatically inherit device placement. The explicit device assignment ensures all components operate on the same device, preventing tensor device mismatch errors.\n",
    "\n",
    "### Initialization Verification\n",
    "\n",
    "The successful initialization confirms:\n",
    "- **Model architecture**: All layers are properly instantiated\n",
    "- **Memory system**: Configuration is valid and applied\n",
    "- **Device placement**: All components are on the optimal compute device\n",
    "- **Hook readiness**: The system is prepared for memory hook registration\n",
    "\n",
    "This initialization process establishes a fully functional CMRTransformer instance ready for memory-enhanced operations while maintaining flexibility and compatibility across different deployment scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5999842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMRTransformer ready on mps\n"
     ]
    }
   ],
   "source": [
    "# C1 â€” Instantiate CMRTransformer\n",
    "\n",
    "# Minimal config object with only required fields\n",
    "base_cfg = SimpleNamespace(vocab_size=50257, num_hidden_layers=8)\n",
    "\n",
    "memory_config = {\n",
    "    \"target_layers\": TARGET_LAYERS,\n",
    "    \"buffer_size\": BUFFER_SIZE,\n",
    "}\n",
    "\n",
    "cmr = CMRTransformer(config=base_cfg, memory_config=memory_config)\n",
    "cmr.to(DEVICE)\n",
    "\n",
    "# Ensure nested layers move too (workaround for SimpleNamespace)\n",
    "if hasattr(cmr, \"transformer\") and hasattr(cmr.transformer, \"h\"):\n",
    "    for lyr in cmr.transformer.h:\n",
    "        lyr.to(DEVICE)\n",
    "\n",
    "print(\"CMRTransformer ready on\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749d0f5",
   "metadata": {},
   "source": [
    "## Target Layer Validation and Architecture Verification\n",
    "\n",
    "This critical validation step ensures that the configured target layers exist within the model architecture and can safely have memory hooks installed. This validation prevents runtime errors and provides transparency into the model's layer structure.\n",
    "\n",
    "### Architecture Inspection\n",
    "\n",
    "The validation process examines the actual transformer architecture:\n",
    "\n",
    "#### Layer Count Verification\n",
    "```python\n",
    "num_layers = len(cmr.transformer.h)\n",
    "```\n",
    "Directly counts the number of hidden layers in the transformer by examining the `h` attribute, which contains the layer list in most transformer implementations.\n",
    "\n",
    "#### Range Validation\n",
    "```python\n",
    "invalid = [idx for idx in TARGET_LAYERS if idx < 0 or idx >= num_layers]\n",
    "```\n",
    "Systematically checks each target layer index against the valid range:\n",
    "- **Lower bound**: Prevents negative indices that could cause unexpected behavior\n",
    "- **Upper bound**: Ensures indices don't exceed the actual number of layers\n",
    "- **Comprehensive check**: Validates all target layers in a single operation\n",
    "\n",
    "### Validation Results and Error Handling\n",
    "\n",
    "The validation provides clear feedback about configuration validity:\n",
    "\n",
    "#### Success Case\n",
    "When all target layers are valid, the system confirms:\n",
    "- Total number of layers in the model\n",
    "- List of target layers that will have hooks installed\n",
    "- Confirmation that all targets are within valid range\n",
    "\n",
    "#### Error Case\n",
    "If invalid layers are detected, the system:\n",
    "- Identifies specific problematic layer indices\n",
    "- Provides clear warning messages\n",
    "- Allows the user to correct the configuration before proceeding\n",
    "\n",
    "### Architectural Insights\n",
    "\n",
    "This validation step also provides valuable insights into the model structure:\n",
    "- **Model depth**: Understanding how many layers are available for memory capture\n",
    "- **Layer accessibility**: Confirming that the transformer structure is compatible with hook installation\n",
    "- **Configuration optimization**: Helping users select optimal layer combinations\n",
    "\n",
    "### Best Practices for Layer Selection\n",
    "\n",
    "The validation enables informed layer selection decisions:\n",
    "- **Early layers** (0-2): Capture token-level and syntactic features\n",
    "- **Middle layers** (3-5): Capture semantic and conceptual representations\n",
    "- **Later layers** (6+): Capture high-level reasoning and task-specific features\n",
    "\n",
    "This validation framework ensures robust, error-free operation while providing transparency and guidance for optimal memory system configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49edd11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 8, 'TARGET_LAYERS': [2, 4]}\n",
      "All target layers are valid.\n"
     ]
    }
   ],
   "source": [
    "# C2 â€” Validate target layers\n",
    "num_layers = len(cmr.transformer.h)\n",
    "invalid = [idx for idx in TARGET_LAYERS if idx < 0 or idx >= num_layers]\n",
    "print({\"num_layers\": num_layers, \"TARGET_LAYERS\": TARGET_LAYERS})\n",
    "if invalid:\n",
    "    print(\"Warning: some target layers are out of range:\", invalid)\n",
    "else:\n",
    "    print(\"All target layers are valid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fe861",
   "metadata": {},
   "source": [
    "## Memory Hook Registration and Activation\n",
    "\n",
    "This section demonstrates the activation of the CMR system's core memory capture mechanism through the registration of forward hooks on specified transformer layers. Hook registration is the critical step that enables real-time memory capture during model inference.\n",
    "\n",
    "### Hook Registration Process\n",
    "\n",
    "The `register_memory_hooks()` method installs forward hooks on the target layers:\n",
    "\n",
    "#### Automatic Hook Installation\n",
    "```python\n",
    "cmr.register_memory_hooks()\n",
    "```\n",
    "This single method call:\n",
    "- Iterates through all specified target layers\n",
    "- Installs custom forward hooks on each layer\n",
    "- Configures hooks to capture hidden states during forward passes\n",
    "- Registers hooks in the model's hook registry for later management\n",
    "\n",
    "#### Hook Functionality\n",
    "Each registered hook performs several critical functions:\n",
    "- **State Capture**: Extracts hidden states as they pass through the layer\n",
    "- **Metadata Collection**: Records layer index, sequence position, and timing information\n",
    "- **Relevance Scoring**: Applies initial relevance assessment to captured states\n",
    "- **Memory Storage**: Adds captured states to the appropriate memory buffer\n",
    "\n",
    "### Hook Registry Management\n",
    "\n",
    "The system maintains a comprehensive registry of active hooks:\n",
    "\n",
    "#### Registry Structure\n",
    "```python\n",
    "active_hook_layers = sorted(list(cmr.layer_hooks.keys()))\n",
    "```\n",
    "The `layer_hooks` dictionary maps layer indices to their respective hook handles, enabling:\n",
    "- **Hook tracking**: Know exactly which layers have active hooks\n",
    "- **Selective management**: Enable/disable hooks on specific layers\n",
    "- **Cleanup operations**: Properly remove hooks when no longer needed\n",
    "\n",
    "#### Registry Benefits\n",
    "- **Transparency**: Clear visibility into which layers are being monitored\n",
    "- **Control**: Ability to dynamically modify hook configuration\n",
    "- **Debugging**: Easy identification of hook-related issues\n",
    "- **Resource management**: Proper cleanup prevents memory leaks\n",
    "\n",
    "### Memory System Activation\n",
    "\n",
    "Hook registration activates the memory system's core functionality:\n",
    "\n",
    "#### Real-time Capture\n",
    "Once hooks are registered, every forward pass through the model will:\n",
    "- Automatically capture hidden states from target layers\n",
    "- Apply relevance scoring to determine memory worthiness\n",
    "- Store significant states in layer-specific memory buffers\n",
    "- Update sequence tracking and metadata\n",
    "\n",
    "#### Performance Considerations\n",
    "The hook system is designed for minimal performance impact:\n",
    "- **Selective capture**: Only specified layers are monitored\n",
    "- **Efficient storage**: States are processed and stored asynchronously\n",
    "- **Memory management**: Automatic buffer management prevents memory overflow\n",
    "- **Optional activation**: Hooks can be disabled when memory capture isn't needed\n",
    "\n",
    "This hook registration system provides the foundation for all memory-enhanced operations, enabling the CMR system to learn from and remember important contextual information across interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fc7066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active hook layers: [2, 4]\n"
     ]
    }
   ],
   "source": [
    "# C3 â€” Register memory hooks\n",
    "cmr.register_memory_hooks()\n",
    "active_hook_layers = sorted(list(cmr.layer_hooks.keys()))\n",
    "print(\"Active hook layers:\", active_hook_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8098f1a",
   "metadata": {},
   "source": [
    "## Advanced Tokenization System with Dual-Mode Support\n",
    "\n",
    "This section implements a sophisticated tokenization system that seamlessly supports both production-grade HuggingFace tokenizers and a lightweight fallback tokenizer. This dual-mode approach ensures compatibility across development and production environments while maintaining consistent functionality.\n",
    "\n",
    "### Toy Tokenizer Implementation\n",
    "\n",
    "The toy tokenizer provides a simple but effective fallback mechanism:\n",
    "\n",
    "#### Vocabulary Management\n",
    "```python\n",
    "toy_vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "```\n",
    "Maintains a dynamic vocabulary that grows during processing:\n",
    "- **Special tokens**: Includes padding and unknown token handling\n",
    "- **Dynamic expansion**: Automatically adds new tokens as they're encountered\n",
    "- **Consistent mapping**: Maintains stable token-to-ID mappings throughout the session\n",
    "\n",
    "#### Encoding Process\n",
    "```python\n",
    "def toy_encode(text: str):\n",
    "    tokens = text.strip().split()\n",
    "    # Dynamic vocabulary expansion with unknown token fallback\n",
    "```\n",
    "- **Whitespace tokenization**: Simple but effective for many use cases\n",
    "- **Vocabulary growth**: Adds new tokens to vocabulary automatically\n",
    "- **Fallback handling**: Uses `<unk>` token for unmapped tokens\n",
    "\n",
    "#### Decoding Process\n",
    "```python\n",
    "def toy_decode(ids):\n",
    "    inv_vocab = {i: t for t, i in toy_vocab.items()}\n",
    "    return \" \".join(inv_vocab.get(i, \"<unk>\") for i in ids)\n",
    "```\n",
    "- **Inverse mapping**: Creates reverse vocabulary for ID-to-token conversion\n",
    "- **Error handling**: Gracefully handles unknown token IDs\n",
    "- **String reconstruction**: Rebuilds original text structure\n",
    "\n",
    "### Production Tokenizer Integration\n",
    "\n",
    "The system prioritizes HuggingFace tokenizers when available:\n",
    "\n",
    "#### Automatic Tokenizer Selection\n",
    "```python\n",
    "if hf_tokenizer is not None:\n",
    "    ids = hf_tokenizer.encode(text, add_special_tokens=False)\n",
    "else:\n",
    "    ids = toy_encode(text)\n",
    "```\n",
    "- **Conditional usage**: Automatically selects the best available tokenizer\n",
    "- **Configuration control**: Disables special tokens to maintain consistency\n",
    "- **Seamless fallback**: Transparently falls back to toy tokenizer if needed\n",
    "\n",
    "### Unified Interface Functions\n",
    "\n",
    "The encode/decode functions provide a consistent interface regardless of the underlying tokenizer:\n",
    "\n",
    "#### Encoding Interface\n",
    "```python\n",
    "def encode(text: str) -> torch.LongTensor:\n",
    "    # Handles both HF and toy tokenizers\n",
    "    # Returns properly shaped tensor on correct device\n",
    "```\n",
    "- **Device management**: Ensures tensors are on the correct compute device\n",
    "- **Shape consistency**: Always returns [1, T] shaped tensors for model compatibility\n",
    "- **Error handling**: Provides fallback for empty or problematic inputs\n",
    "\n",
    "#### Decoding Interface\n",
    "```python\n",
    "def decode(ids: torch.LongTensor) -> str:\n",
    "    # Unified decoding regardless of tokenizer type\n",
    "    # Handles tensor conversion and device management\n",
    "```\n",
    "- **Tensor handling**: Converts PyTorch tensors to appropriate list format\n",
    "- **Device agnostic**: Works with tensors on any device (CPU/GPU/MPS)\n",
    "- **Type flexibility**: Handles various input tensor shapes and formats\n",
    "\n",
    "### Benefits of Dual-Mode Design\n",
    "\n",
    "This tokenization system provides several key advantages:\n",
    "- **Development flexibility**: Lightweight toy tokenizer for rapid prototyping\n",
    "- **Production readiness**: Full HuggingFace tokenizer support for deployment\n",
    "- **Compatibility**: Works across different model architectures and configurations\n",
    "- **Debugging**: Simple toy tokenizer aids in system debugging and testing\n",
    "- **Resource efficiency**: Minimal overhead when full tokenization isn't needed\n",
    "\n",
    "This comprehensive tokenization framework ensures that the CMR system can operate effectively across a wide range of scenarios while maintaining consistent behavior and optimal performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a8b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_encode(text: str):\n",
    "    tokens = text.strip().split()\n",
    "    ids = []\n",
    "    for tok in tokens:\n",
    "        if tok not in toy_vocab:\n",
    "            toy_vocab[tok] = len(toy_vocab)\n",
    "        ids.append(toy_vocab.get(tok, toy_vocab[\"<unk>\"]))\n",
    "    return ids\n",
    "\n",
    "def toy_decode(ids):\n",
    "    inv_vocab = {i: t for t, i in toy_vocab.items()}\n",
    "    return \" \".join(inv_vocab.get(i, \"<unk>\") for i in ids)\n",
    "\n",
    "def encode(text: str) -> torch.LongTensor:\n",
    "    if hf_tokenizer is not None:\n",
    "        ids = hf_tokenizer.encode(text, add_special_tokens=False)\n",
    "    else:\n",
    "        ids = toy_encode(text)\n",
    "    if len(ids) == 0:\n",
    "        ids = [toy_vocab.get(\"<unk>\", 1)]\n",
    "    return torch.tensor(ids, dtype=torch.long, device=DEVICE).unsqueeze(0)  # [1, T]\n",
    "\n",
    "def decode(ids: torch.LongTensor) -> str:\n",
    "    arr = ids.detach().cpu().view(-1).tolist()\n",
    "    if hf_tokenizer is not None:\n",
    "        return hf_tokenizer.decode(arr)\n",
    "    return toy_decode(arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b70e166",
   "metadata": {},
   "source": [
    "## HuggingFace Tokenizer Setup and Configuration\n",
    "\n",
    "This section demonstrates the intelligent initialization of production-grade tokenizers with automatic fallback capabilities. The setup process prioritizes HuggingFace tokenizers when available while maintaining robust error handling for various deployment scenarios.\n",
    "\n",
    "### Conditional Tokenizer Loading\n",
    "\n",
    "The system implements a safe tokenizer loading strategy:\n",
    "\n",
    "#### Primary Tokenizer Attempt\n",
    "```python\n",
    "if USE_HF_TOKENIZER:\n",
    "    try:\n",
    "        from transformers import AutoTokenizer\n",
    "        hf_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "```\n",
    "When HuggingFace tokenization is enabled, the system:\n",
    "- **Dynamic import**: Imports the AutoTokenizer class only when needed\n",
    "- **Model-specific loading**: Loads the tokenizer that matches the specified model\n",
    "- **Automatic configuration**: Inherits optimal settings from the pre-trained model\n",
    "\n",
    "#### Graceful Fallback Handling\n",
    "```python\n",
    "except Exception as e:\n",
    "    print(\"Falling back to toy tokenizer (HF load failed):\", e)\n",
    "    hf_tokenizer = None\n",
    "```\n",
    "If HuggingFace tokenizer loading fails, the system:\n",
    "- **Error capture**: Catches and logs specific failure reasons\n",
    "- **Graceful degradation**: Falls back to the toy tokenizer without crashing\n",
    "- **User notification**: Provides clear feedback about the fallback behavior\n",
    "\n",
    "### Tokenizer Selection Benefits\n",
    "\n",
    "The intelligent tokenizer selection provides several advantages:\n",
    "\n",
    "#### Production Readiness\n",
    "- **Model compatibility**: Perfect alignment with the target model's vocabulary\n",
    "- **Subword tokenization**: Advanced tokenization strategies (BPE, SentencePiece)\n",
    "- **Special token handling**: Proper management of model-specific special tokens\n",
    "- **Encoding optimization**: Optimal token sequence generation for the target model\n",
    "\n",
    "#### Development Flexibility\n",
    "- **Offline development**: Works without internet access using toy tokenizer\n",
    "- **Rapid prototyping**: Lightweight fallback for quick testing and development\n",
    "- **Dependency resilience**: Continues operation even if HuggingFace libraries are unavailable\n",
    "- **Cross-platform compatibility**: Reduces dependency-related deployment issues\n",
    "\n",
    "### Configuration Impact\n",
    "\n",
    "The tokenizer choice affects system behavior:\n",
    "\n",
    "#### With HuggingFace Tokenizer\n",
    "- **Precise tokenization**: Exact match with model training tokenization\n",
    "- **Optimal performance**: Best possible model performance and accuracy\n",
    "- **Full feature support**: Access to all model-specific tokenization features\n",
    "\n",
    "#### With Toy Tokenizer\n",
    "- **Simplified processing**: Basic whitespace-based tokenization\n",
    "- **Development efficiency**: Fast iteration and testing cycles\n",
    "- **Reduced dependencies**: Minimal external library requirements\n",
    "- **Educational clarity**: Easy to understand and modify tokenization behavior\n",
    "\n",
    "This flexible tokenizer setup ensures that the CMR system can operate effectively across diverse environments while maintaining optimal performance when full tokenization capabilities are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9221ae6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HF tokenizer for: google/gemma-3-4b-it\n"
     ]
    }
   ],
   "source": [
    "if USE_HF_TOKENIZER:\n",
    "    try:\n",
    "        from transformers import AutoTokenizer\n",
    "        hf_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        print(\"Using HF tokenizer for:\", MODEL_NAME)\n",
    "    except Exception as e:\n",
    "        print(\"Falling back to toy tokenizer (HF load failed):\", e)\n",
    "        hf_tokenizer = None\n",
    "else:\n",
    "    print(\"Using toy tokenizer (default)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755139a",
   "metadata": {},
   "source": [
    "## Contextual Memory Search and Advanced Retrieval System\n",
    "\n",
    "This section demonstrates the CMR system's memory search capabilities through scenario processing and implements a sophisticated text-based retrieval mechanism. The system showcases how captured memories can be queried and retrieved based on contextual relevance.\n",
    "\n",
    "### Scenario Processing and Memory Population\n",
    "\n",
    "The system processes the comprehensive web application scenario to populate memory buffers:\n",
    "\n",
    "#### Sequential Processing\n",
    "Each scenario entry is processed through the CMR system:\n",
    "- **Encoding**: Text descriptions are tokenized and converted to model inputs\n",
    "- **Forward pass**: Content flows through the transformer with active memory hooks\n",
    "- **Memory capture**: Hidden states are captured and stored in layer-specific buffers\n",
    "- **Metadata recording**: Each memory entry includes step number, privacy classification, and contextual information\n",
    "\n",
    "#### Privacy-Aware Processing\n",
    "The scenario processing respects privacy boundaries:\n",
    "- **Public content** (ðŸ”“): Openly processed and stored in standard memory buffers\n",
    "- **Private content** (ðŸ”’): Marked with privacy flags and subject to access controls\n",
    "- **Contextual awareness**: The system learns to distinguish between public and private information patterns\n",
    "\n",
    "### Hidden State Analysis and Scoring\n",
    "\n",
    "The system performs sophisticated analysis of captured hidden states:\n",
    "\n",
    "#### Variance-Based Scoring\n",
    "```python\n",
    "scores = torch.var(last_hidden, dim=-1).squeeze(0)  # [T]\n",
    "```\n",
    "Uses variance across the hidden dimension as a relevance metric:\n",
    "- **Information content**: High variance indicates rich, diverse information\n",
    "- **Attention patterns**: Variance correlates with model attention and importance\n",
    "- **Sequence analysis**: Scores each position in the sequence independently\n",
    "\n",
    "#### Score Normalization\n",
    "```python\n",
    "scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "```\n",
    "Normalizes scores to [0,1] range for consistent interpretation:\n",
    "- **Comparative ranking**: Enables comparison across different sequences\n",
    "- **Threshold application**: Facilitates relevance threshold enforcement\n",
    "- **Stability**: Epsilon term prevents division-by-zero errors\n",
    "\n",
    "### Text-Based Memory Retrieval System\n",
    "\n",
    "The implementation includes a practical text retrieval system for memory search:\n",
    "\n",
    "#### Token-Based Similarity\n",
    "```python\n",
    "def _tokens(s: str):\n",
    "    return set(re.findall(r\"[a-z0-9]+\", s.lower()))\n",
    "```\n",
    "Extracts meaningful tokens using regex pattern matching:\n",
    "- **Normalization**: Converts to lowercase for case-insensitive matching\n",
    "- **Alphanumeric focus**: Captures words and numbers while excluding punctuation\n",
    "- **Set representation**: Enables efficient set operations for similarity calculation\n",
    "\n",
    "#### Jaccard Similarity Scoring\n",
    "```python\n",
    "j = len(q & t) / (len(q | t) + 1e-6)\n",
    "```\n",
    "Implements Jaccard similarity for relevance scoring:\n",
    "- **Intersection over union**: Measures overlap relative to total unique tokens\n",
    "- **Range**: Produces scores between 0 (no overlap) and 1 (identical)\n",
    "- **Efficiency**: Set operations provide fast similarity computation\n",
    "\n",
    "#### Stopword Filtering\n",
    "```python\n",
    "def remove_stop_words(text: str):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "```\n",
    "Removes common words to focus on meaningful content:\n",
    "- **Noise reduction**: Eliminates high-frequency, low-information words\n",
    "- **Relevance enhancement**: Improves similarity scoring accuracy\n",
    "- **Query optimization**: Focuses retrieval on semantically important terms\n",
    "\n",
    "### Memory Search Results and Ranking\n",
    "\n",
    "The system demonstrates practical memory retrieval:\n",
    "\n",
    "#### Top-K Retrieval\n",
    "The system retrieves the most relevant memories based on query similarity:\n",
    "- **Ranked results**: Returns memories ordered by relevance score\n",
    "- **Configurable K**: Allows control over the number of retrieved memories\n",
    "- **Context snippets**: Provides actual text content for immediate use\n",
    "\n",
    "#### Example Query Results\n",
    "For the query \"I want to see the billing page\", the system returns:\n",
    "1. **Billing page**: Direct match with payment methods and subscription management\n",
    "2. **Pricing page**: Related content with billing and payment information\n",
    "3. **Compliance Dashboard**: Contextually related financial and regulatory content\n",
    "\n",
    "This comprehensive memory search system demonstrates the CMR's ability to capture, store, and intelligently retrieve contextual information, providing the foundation for memory-enhanced language model interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f366e417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”“ Step 1: Home â€” Home page: company overview, featured products, testimonials, and call-to-action buttons for sign-up.\n",
      "ðŸ”“ Step 2: About â€” About page: company history, mission statement, team bios, and office locations with contact details.\n",
      "ðŸ”“ Step 3: Products â€” Products page: catalog of available services with pricing tiers, feature comparisons, and demo videos.\n",
      "ðŸ”“ Step 4: Contact â€” Contact page: contact form, phone numbers, email addresses, live chat widget, and business hours.\n",
      "ðŸ”“ Step 5: Blog â€” Blog page: articles, tutorials, industry news, and SEO-optimized content with comment sections.\n",
      "ðŸ”“ Step 6: Pricing â€” Pricing page: subscription plans, feature matrix, annual vs monthly billing, and enterprise quotes.\n",
      "ðŸ”“ Step 7: Faq â€” FAQ page: common questions organized by category with search functionality and helpful resources.\n",
      "ðŸ”“ Step 8: Terms Of Service â€” Terms of Service page: legal agreements, user responsibilities, limitation of liability, and dispute resolution.\n",
      "ðŸ”“ Step 9: Privacy Policy â€” Privacy Policy page: data collection practices, cookie usage, third-party integrations, and user rights.\n",
      "ðŸ”“ Step 10: Careers â€” Careers page: open positions, company culture, benefits overview, and application submission portal.\n",
      "ðŸ”“ Step 11: Login â€” Login page: user authentication with email/password, social login options, and forgot password recovery.\n",
      "ðŸ”“ Step 12: Register â€” Register page: new user sign-up form with email verification, terms acceptance, and account activation.\n",
      "ðŸ”“ Step 13: User Dashboard â€” User Dashboard: personalized homepage showing account status, recent activity, and quick action buttons.\n",
      "ðŸ”“ Step 14: Profile Settings â€” Profile Settings: user information management, password changes, notification preferences, and account deletion.\n",
      "ðŸ”“ Step 15: Billing â€” Billing page: payment methods, invoice history, subscription management, and upgrade/downgrade options.\n",
      "ðŸ”“ Step 16: Order History â€” Order History: past purchases, order tracking, return requests, and downloadable receipts.\n",
      "ðŸ”“ Step 17: Shopping Cart â€” Shopping Cart: selected items, quantity adjustments, coupon codes, and checkout initiation.\n",
      "ðŸ”“ Step 18: Checkout â€” Checkout page: shipping information, payment processing, order review, and purchase confirmation.\n",
      "ðŸ”“ Step 19: Search Results â€” Search Results: product/content listings with filters, sorting options, and pagination controls.\n",
      "ðŸ”“ Step 20: Help Center â€” Help Center: knowledge base articles, video tutorials, troubleshooting guides, and ticket submission.\n",
      "ðŸ”“ Step 21: Api Documentation â€” API Documentation: endpoint references, authentication methods, code examples, and rate limiting info.\n",
      "ðŸ”“ Step 22: Downloads â€” Downloads page: software installers, user manuals, templates, and resource files with version history.\n",
      "ðŸ”“ Step 23: News â€” News page: press releases, company announcements, media coverage, and investor relations updates.\n",
      "ðŸ”“ Step 24: Events â€” Events page: upcoming webinars, conferences, product launches, and registration forms.\n",
      "ðŸ”“ Step 25: Partners â€” Partners page: integration listings, affiliate program details, and partner application process.\n",
      "ðŸ”“ Step 26: Sitemap â€” Sitemap page: hierarchical website structure with all public pages listed and organized by category.\n",
      "ðŸ”“ Step 27: 404 Error â€” 404 Error page: custom not found message with navigation suggestions and search functionality.\n",
      "ðŸ”“ Step 28: Maintenance â€” Maintenance page: scheduled downtime notification with estimated completion time and status updates.\n",
      "ðŸ”“ Step 29: Security â€” Security page: data protection measures, compliance certifications, and security best practices.\n",
      "ðŸ”“ Step 30: Mobile App â€” Mobile App page: download links for iOS/Android, feature highlights, and screenshot gallery.\n",
      "ðŸ”“ Step 31: Integrations â€” Integrations page: third-party service connections, setup instructions, and compatibility matrix.\n",
      "ðŸ”’ Step 32: Admin Dashboard â€” Admin Dashboard: system overview, user management controls, analytics data, and configuration settings. Contains administrative functions.\n",
      "ðŸ”’ Step 33: User Management â€” User Management: admin interface for viewing user accounts, permissions, suspension controls, and personal data. Contains PII.\n",
      "ðŸ”’ Step 34: Analytics Panel â€” Analytics Panel: detailed usage statistics, user behavior tracking, conversion metrics, and sensitive business data.\n",
      "ðŸ”’ Step 35: Database Admin â€” Database Admin: direct database access, query execution, backup management, and sensitive system data.\n",
      "ðŸ”’ Step 36: Financial Reports â€” Financial Reports: revenue data, transaction details, tax information, and confidential business metrics.\n",
      "ðŸ”’ Step 37: Employee Portal â€” Employee Portal: staff directory, salary information, performance reviews, and internal communications. Contains PII.\n",
      "ðŸ”’ Step 38: System Logs â€” System Logs: server logs, error tracking, security events, and debugging information with user data.\n",
      "ðŸ”’ Step 39: Configuration Manager â€” Configuration Manager: system settings, API keys, database credentials, and infrastructure management.\n",
      "ðŸ”’ Step 40: Backup Interface â€” Backup Interface: data recovery tools, backup scheduling, restore functions, and system maintenance access.\n",
      "ðŸ”’ Step 41: Security Center â€” Security Center: threat monitoring, access logs, vulnerability scans, and incident response tools.\n",
      "ðŸ”’ Step 42: Payment Processing â€” Payment Processing: transaction management, refund processing, merchant settings, and financial data access.\n",
      "ðŸ”’ Step 43: Customer Support Admin â€” Customer Support Admin: ticket management, user impersonation, chat monitoring, and PII access for support.\n",
      "ðŸ”’ Step 44: Marketing Analytics â€” Marketing Analytics: campaign performance, customer segments, A/B test results, and behavioral data.\n",
      "ðŸ”’ Step 45: Content Management â€” Content Management: CMS backend, publishing controls, media library, and editorial workflow management.\n",
      "ðŸ”’ Step 46: Api Management â€” API Management: endpoint monitoring, rate limiting controls, usage analytics, and developer key management.\n",
      "ðŸ”’ Step 47: Audit Trail â€” Audit Trail: compliance logging, user activity tracking, data access records, and regulatory reporting.\n",
      "ðŸ”’ Step 48: Hr Management â€” HR Management: employee records, hiring pipeline, payroll data, and confidential personnel information. Contains PII.\n",
      "ðŸ”’ Step 49: Legal Documents Manager â€” Legal Documents Manager: contracts, NDAs, compliance files, and confidential legal correspondence.\n",
      "ðŸ”’ Step 50: Vendor Management â€” Vendor Management: supplier contracts, payment processing, vendor onboarding, and procurement data.\n",
      "ðŸ”’ Step 51: Executive Dashboard â€” Executive Dashboard: board reports, strategic metrics, competitive analysis, and confidential business intelligence.\n",
      "ðŸ”’ Step 52: Data Export Tool â€” Data Export Tool: bulk data extraction, customer information downloads, and sensitive data migration utilities. Contains PII.\n",
      "ðŸ”’ Step 53: Email Campaign Manager â€” Email Campaign Manager: subscriber lists, email templates, delivery tracking, and customer communication data.\n",
      "ðŸ”’ Step 54: Inventory Management â€” Inventory Management: stock levels, supplier information, cost data, and warehouse operations interface.\n",
      "ðŸ”’ Step 55: Customer Service Tools â€” Customer Service Tools: case management, escalation procedures, customer history access, and support metrics.\n",
      "ðŸ”’ Step 56: Quality Assurance â€” Quality Assurance: testing environments, bug tracking, performance monitoring, and development tools access.\n",
      "ðŸ”’ Step 57: Compliance Dashboard â€” Compliance Dashboard: regulatory reporting, audit preparation, policy management, and risk assessment tools.\n",
      "Top positions:\n",
      "#1: pos=4, score=0.994\n",
      "#2: pos=9, score=0.994\n",
      "#3: pos=6, score=0.764\n",
      "#4: pos=3, score=0.688\n",
      "#5: pos=10, score=0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/mq3cq_z505nbzy4_cw1s4x_00000gn/T/ipykernel_13769/2660531025.py:30: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
      "Consider using tensor.detach() first. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
      "  print(f\"#{rank+1}: pos={int(idxs[rank])}, score={float(vals[rank]):.3f}\")\n"
     ]
    }
   ],
   "source": [
    "# E3 â€” Storyboard (emoji)\n",
    "for r in rows:\n",
    "    lock = \"ðŸ”’\" if r[\"Privacy\"] == \"Private\" else \"ðŸ”“\"\n",
    "    print(f\"{lock} Step {r['Step']}: {r['Page']} â€” {r['Description']}\")\n",
    "\n",
    "\n",
    "# I2 â€” Score positions on the last run's hidden states\n",
    "# Reuse the last call's enhanced hidden states if available\n",
    "try:\n",
    "    last_hidden = outputs.get(\"last_hidden_state\")  # [1, T, H]\n",
    "except Exception:\n",
    "    last_hidden = None\n",
    "\n",
    "if last_hidden is None:\n",
    "    # Fallback: run one more step to get hidden states\n",
    "    tmp = cmr(encode(SCENARIO[-1][\"text\"]))\n",
    "    last_hidden = tmp.get(\"last_hidden_state\")\n",
    "\n",
    "# Simple variance-based scoring over hidden dim\n",
    "scores = torch.var(last_hidden, dim=-1).squeeze(0)  # [T]\n",
    "# Normalize to [0,1]\n",
    "if scores.numel() > 0:\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "\n",
    "# Show top-5 positions\n",
    "k = min(5, scores.numel())\n",
    "vals, idxs = torch.topk(scores, k)\n",
    "print(\"Top positions:\")\n",
    "for rank in range(k):\n",
    "    print(f\"#{rank+1}: pos={int(idxs[rank])}, score={float(vals[rank]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56312b",
   "metadata": {},
   "source": [
    "## Memory Search Results Analysis and Decoding\n",
    "\n",
    "This final section demonstrates the practical application of the CMR system's memory retrieval capabilities, showing how captured memory states can be effectively searched and retrieved to provide contextually relevant information for user queries.\n",
    "\n",
    "### Memory State Analysis and Ranking\n",
    "\n",
    "The system analyzes the last processed hidden states to identify the most informative positions:\n",
    "\n",
    "#### Information Content Scoring\n",
    "The variance-based scoring mechanism identifies positions with high information content:\n",
    "- **Variance analysis**: Higher variance indicates richer, more diverse semantic information\n",
    "- **Position ranking**: Each token position receives a relevance score based on its hidden state variance\n",
    "- **Top-K selection**: The system identifies the 5 most informative positions for detailed analysis\n",
    "\n",
    "#### Practical Results Interpretation\n",
    "The scoring results provide insights into which parts of the processed content contain the most significant information:\n",
    "- **High-scoring positions**: Typically correspond to key concepts, entities, or important semantic content\n",
    "- **Score distribution**: The normalized scores range from 0 to 1, enabling threshold-based filtering\n",
    "- **Sequence analysis**: Position-level scoring allows fine-grained understanding of content importance\n",
    "\n",
    "### Text-Based Memory Retrieval Demonstration\n",
    "\n",
    "The implementation showcases a practical memory search system using the web application scenario:\n",
    "\n",
    "#### Query Processing Pipeline\n",
    "```python\n",
    "USER_QUERY = remove_stop_words(\"I want to see the billing page\")\n",
    "context_snippets = retrieve_top_text_memories(USER_QUERY, k=3)\n",
    "```\n",
    "\n",
    "The query processing involves several steps:\n",
    "- **Stopword removal**: Eliminates common words to focus on meaningful terms\n",
    "- **Token extraction**: Identifies key search terms for similarity matching\n",
    "- **Relevance scoring**: Applies Jaccard similarity to rank memory entries\n",
    "- **Top-K retrieval**: Returns the most relevant memory snippets\n",
    "\n",
    "#### Retrieved Memory Examples\n",
    "\n",
    "For the billing-related query, the system successfully retrieves:\n",
    "\n",
    "1. **Primary match**: \"Billing page: payment methods, invoice history, subscription management, and upgrade/downgrade options\"\n",
    "   - **Direct relevance**: Exact match for \"billing page\" query\n",
    "   - **Comprehensive content**: Includes related billing functionality\n",
    "\n",
    "2. **Secondary match**: \"Pricing page: subscription plans, feature matrix, annual vs monthly billing, and enterprise quotes\"\n",
    "   - **Semantic relevance**: Related to billing through pricing and subscription concepts\n",
    "   - **Contextual connection**: Billing and pricing are closely related domains\n",
    "\n",
    "3. **Tertiary match**: \"Compliance Dashboard: regulatory reporting, audit preparation, policy management, and risk assessment tools\"\n",
    "   - **Domain relevance**: Financial compliance relates to billing and payment processing\n",
    "   - **Business context**: Demonstrates the system's understanding of business relationships\n",
    "\n",
    "### System Capabilities Demonstrated\n",
    "\n",
    "This memory search demonstration showcases several key CMR capabilities:\n",
    "\n",
    "#### Contextual Understanding\n",
    "- **Semantic associations**: The system understands relationships between billing, pricing, and compliance\n",
    "- **Domain knowledge**: Demonstrates awareness of business domain connections\n",
    "- **Relevance ranking**: Properly orders results by contextual similarity\n",
    "\n",
    "#### Practical Utility\n",
    "- **Real-time retrieval**: Fast search and retrieval of relevant information\n",
    "- **Flexible querying**: Works with natural language queries\n",
    "- **Scalable approach**: Efficient similarity computation for large memory stores\n",
    "\n",
    "#### Privacy Awareness\n",
    "- **Content classification**: The system maintains awareness of public vs. private content\n",
    "- **Access control ready**: Foundation for implementing privacy-preserving retrieval\n",
    "- **Compliance support**: Demonstrates handling of sensitive information categories\n",
    "\n",
    "This comprehensive demonstration illustrates how the CMR system transforms captured hidden states into a practical, searchable memory system that can enhance language model performance through intelligent context retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07cdd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Billing page: payment methods, invoice history, subscription management, and upgrade/downgrade options.',\n",
       " 'Pricing page: subscription plans, feature matrix, annual vs monthly billing, and enterprise quotes.',\n",
       " 'Compliance Dashboard: regulatory reporting, audit preparation, policy management, and risk assessment tools.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _tokens(s: str):\n",
    "    return set(re.findall(r\"[a-z0-9]+\", s.lower()))\n",
    "\n",
    "# Map scenario index to text for retrieval\n",
    "SCEN_TEXTS = [it[\"text\"] for it in SCENARIO] if 'SCENARIO' in globals() else []\n",
    "\n",
    "def retrieve_top_text_memories(query_text: str, k: int = 3):\n",
    "    if not SCEN_TEXTS:\n",
    "        return []\n",
    "    q = _tokens(query_text)\n",
    "    scored = []\n",
    "    for idx, txt in enumerate(SCEN_TEXTS):\n",
    "        t = _tokens(txt)\n",
    "        j = len(q & t) / (len(q | t) + 1e-6)\n",
    "        scored.append((j, idx, txt))\n",
    "    scored.sort(reverse=True)\n",
    "    return [txt for _, _, txt in scored[:k]]\n",
    "\n",
    "def remove_stop_words(text: str):\n",
    "    return \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
    "\n",
    "USER_QUERY = remove_stop_words(\"I want to see the billing page \")\n",
    "context_snippets = retrieve_top_text_memories(USER_QUERY, k=3)\n",
    "\n",
    "context_snippets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
